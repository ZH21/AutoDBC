{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff9e374",
   "metadata": {},
   "source": [
    "## 1.提取DBC文件信息转为数据域分割的GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c519c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "node = []\n",
    "allDatas = []\n",
    "siganlList = []\n",
    "SignalsName = []\n",
    "messageName = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcc02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file_name):\n",
    "    global node,allDatas,siganlList,SignalsName,messageName\n",
    "    ''' 得到dbc文件的绝对路径'''\n",
    "    filePath = file_name\n",
    "    if filePath:\n",
    "        print(filePath)\n",
    "        f = open(filePath, \"r\")  # 设置文件对象\n",
    "    else:\n",
    "        print(\"读取文件失败！\")\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    NodesPattern:节点\n",
    "    MessagePattern：消息\n",
    "    SignalPattern：信号\n",
    "    \"\"\"\n",
    "    NodesPattern = re.compile(r\"BU_: (.*)\", re.S)\n",
    "    MessagePattern = re.compile(r\"BO_ (.*?) (.*?): (.*?) (.*)\", re.S)\n",
    "#     SignalPattern = re.compile('''SG_ (.*?) : (.*?)\\|(.*?)@.*? \\((.*?),(.*?)\\) \\[(.*?)\\|(.*?)\\] \"(.*?)\" (.*)''', re.S)\n",
    "    SignalPattern = re.compile('''SG_ (.*?) : (.*?)\\|(.*?)@([0-9])([+|-]) \\((.*?),(.*?)\\) \\[(.*?)\\|(.*?)\\] \"(.*?)\" (.*)''', re.S)\n",
    "    DefaultValue = '''BA_ \"GenSig(.*?)\" SG_ (\\d+) signalname (\\d+);'''\n",
    "\n",
    "    line = f.readline()\n",
    "    allDatas=[]\n",
    "    while line:\n",
    "        \"\"\" 匹配出节点 \"\"\"\n",
    "        NodesSearched = re.search(NodesPattern, line.strip())\n",
    "        if NodesSearched:\n",
    "            node = NodesSearched.group(1).split(\" \")\n",
    "            #print(node)\n",
    "        \"\"\" 匹配出消息 \"\"\"\n",
    "        MessageSearched = re.search(MessagePattern, line.strip())\n",
    "        if MessageSearched:\n",
    "            siganlList.clear()\n",
    "            \"\"\"如果匹配到了message，则获取到message的相关参数 \n",
    "             比如匹配到了NM_Message_ESC_409，则会解析出改message的一些参数构成list对象['1033', 'NM_Message_ESC_409', '8', 'ESC']\n",
    "             这四个参数分别是 messgage ID ;message name ; messgae dataLenth ,message sender\n",
    "             而且把这个list对象 加在了 siganlList 索引0的位置\n",
    "            \"\"\"\n",
    "            Message = list(MessageSearched.groups())\n",
    "            siganlList.append(Message)\n",
    "            \"\"\" 只 要 message的名字 messageName 列表中\"\"\"\n",
    "            messageName.append(Message[1])\n",
    "            \"\"\"读取下一行\"\"\"\n",
    "            line = f.readline()\n",
    "            \"\"\"因为有些message并没有定义signal，所以 下一行还是message\"\"\"\n",
    "            MessageSearched = re.search(MessagePattern, line.strip())\n",
    "            SignalSearched = re.search(SignalPattern, line.strip())\n",
    "            \"\"\"下一行如果不是message的内容 就一定是signal的内容了\"\"\"\n",
    "            if not MessageSearched:\n",
    "                while SignalSearched:\n",
    "                    \"\"\"获取信号的参数追加到siganlList\"\"\"\n",
    "                    signal = list(SignalSearched.groups())\n",
    "                    siganlList.append(signal)\n",
    "                    \"\"\"只获取 signal name\"\"\"\n",
    "                    SignalsName.append(signal[0])\n",
    "\n",
    "                    # 再次解析信号，直到这个message下的信号全部解析完毕\n",
    "                    line = f.readline()\n",
    "                    SignalSearched = re.search(SignalPattern, line.strip())\n",
    "           # print(siganlList)\n",
    "            c = copy.deepcopy(siganlList)\n",
    "            allDatas.append(c)\n",
    "        else:\n",
    "            line = f.readline()\n",
    "            MessageSearched = re.search(MessagePattern, line.strip())\n",
    "    f.close()  # 将文件关闭\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ae5975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\acura_ilx_2016_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\acura_ilx_2016_nidec.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\acura_rdx_2018_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\acura_rdx_2020_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\bmw_e9x_e8x.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\cadillac_ct6_chassis.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\cadillac_ct6_object.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\cadillac_ct6_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\chrysler_pacifica_2017_hybrid.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\chrysler_pacifica_2017_hybrid_private_fusion.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\comma_body.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\ESR.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\FORD_CADS.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\ford_cgea1_2_bodycan_2011.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\ford_cgea1_2_ptcan_2011.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\ford_fusion_2018_adas.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\ford_fusion_2018_pt.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\ford_lincoln_base_pt.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_chassis.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_high_voltage_management.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_lowspeed.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_lowspeed_1818125.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_object.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_powertrain_expansion.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\gm_global_a_powertrain_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_accord_2018_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_civic_hatchback_ex_2017_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_civic_sedan_16_diesel_2019_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_civic_touring_2016_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_clarity_hybrid_2018_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_crv_executive_2016_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_crv_ex_2017_body_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_crv_ex_2017_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_crv_hybrid_2019_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_crv_touring_2016_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_fit_ex_2018_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_fit_hybrid_2018_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_insight_ex_2019_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_odyssey_exl_2018_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\honda_odyssey_extreme_edition_2018_china_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\hyundai_2015_ccan.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\hyundai_2015_mcan.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\hyundai_i30_2014.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\hyundai_kia_generic.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\hyundai_kia_mando_front_radar.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\luxgen_s5_2015.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\mercedes_benz_e350_2010.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\nissan_leaf_2018.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\nissan_x_trail_2017.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\stellantis_dasm.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\subaru_forester_2017_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\subaru_global_2017_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\subaru_global_2020_hybrid_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\subaru_outback_2015_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\subaru_outback_2019_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\tesla_can.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\tesla_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\tesla_radar.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_2017_ref_pt.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_adas.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_iQ_2009_can.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_new_mc_pt_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_nodsu_pt_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_prius_2010_pt.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_tnga_k_pt_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\toyota_tss2_adas.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\volvo_v40_2017_pt.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\volvo_v60_2015_pt.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\vw_golf_mk4.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\opendbc-master\\\\opendbc-master-delFalseData\\\\vw_mqb_2010.dbc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_names = []\n",
    "path = os.path.abspath('../opendbc-master/opendbc-master-delFalseData')\n",
    "# path = os.path.abspath('./opendbc-master/opendbc-master')\n",
    "dirs = os.listdir(path)                    # 获取指定路径下的文件\n",
    "for i in dirs:\n",
    "    if os.path.splitext(i)[1] == \".dbc\":\n",
    "        file_names.append(os.path.join(path,i))\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583de4e",
   "metadata": {},
   "source": [
    "## 2.处理原始bit数据和GroundTruth数据的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "702784f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_labels(index):\n",
    "    file_name = file_names[index]\n",
    "    readFile(file_name)\n",
    "\n",
    "    # 将DBC文件中的ID(10进制数)改为ID(16进制数)\n",
    "    data_gts = {}\n",
    "    for alldata in allDatas:\n",
    "        data_gts[str(hex(int(alldata[0][0])))[2:]] = alldata\n",
    "\n",
    "    # 得到DBC文件中各ID Message对应信号位置\n",
    "    all_id_lsbs = {}\n",
    "    for k in data_gts.keys():\n",
    "        message = data_gts[k]\n",
    "        lsb_list = []\n",
    "        series = np.zeros(64)\n",
    "        message_id = message[0][0]+\"_\"+message[0][1]\n",
    "        del message[0]\n",
    "        for signal in message:\n",
    "            start = int(signal[1])\n",
    "            length = int(signal[2])\n",
    "            endianness = int(signal[3])\n",
    "            start_row = int(start / 8)\n",
    "            start_col = 8 - (start - start_row * 8) - 1\n",
    "            new_start = start_row * 8 + start_col\n",
    "            if endianness == 0:\n",
    "                new_end = new_start + length\n",
    "                cur_lsb = new_end - 1\n",
    "            if endianness == 1:\n",
    "                cur_lsb = new_start\n",
    "            lsb_list.append(cur_lsb)\n",
    "        all_id_lsbs[k] = lsb_list\n",
    "\n",
    "    # 将各ID Message的信号位置改为 0/1 label\n",
    "    all_id_labels = {}\n",
    "    for k in all_id_lsbs:\n",
    "        cur_lsb_list = all_id_lsbs[k]\n",
    "        cur_label = np.zeros(64)\n",
    "        for cur_lsb in cur_lsb_list:\n",
    "            cur_label[cur_lsb] = 1\n",
    "        all_id_labels[k] = cur_label\n",
    "    return all_id_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f6bad01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(data):\n",
    "    group = data.groupby(by=\"ID\")\n",
    "    id_tracedict = {}\n",
    "    for trace in list(group):\n",
    "        id_tracedict[trace[0]] = trace[1][\"bin\"].apply(lambda x: list(x)).apply(lambda x: list(map(int, x))).tolist()\n",
    "    return id_tracedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "63ba49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(id_tracedict_int, all_id_labels):\n",
    "    ids = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        if(id_tracedict_int.__contains__(id) and all_id_labels.__contains__(id)):\n",
    "            ids.append(id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c271d237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 设置全局的随机种子\n",
    "random.seed(100)\n",
    "# 以id为单位shuffle\n",
    "def get_train_test_ids(id_tracedict, all_id_labels):\n",
    "    ids = get_ids(id_tracedict, all_id_labels)\n",
    "    random.shuffle(ids)\n",
    "    train_len = int(len(ids)*0.7)\n",
    "    train_ids = ids[:train_len]\n",
    "    test_ids = ids[train_len:]\n",
    "    return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "110411d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_data_dict(cur_ids, id_tracedict_int, all_id_labels, trace_data_dict, trace_label_dict): \n",
    "    for id in cur_ids:\n",
    "        trace_data_dict[id] = id_tracedict_int[id]\n",
    "        trace_label_dict[id] = all_id_labels[id]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fd7cd",
   "metadata": {},
   "source": [
    "## 3.综合Honda和Cadillac数据，得到训练集和测试集（包括0/1Label）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c577f",
   "metadata": {},
   "source": [
    "**在ID层面Shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a4c77a0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_dbcs = []\n",
    "cadillac_dbcs = []\n",
    "tesla_dbcs = []\n",
    "for i in range(len(file_names)):\n",
    "    cur_name = file_names[i].split(\"\\\\\")[-1].split(\"_\")[0]\n",
    "    if cur_name == \"honda\":\n",
    "        honda_dbcs.append(i)\n",
    "    if cur_name == \"cadillac\":\n",
    "        cadillac_dbcs.append(i)\n",
    "    if cur_name == \"tesla\":\n",
    "        tesla_dbcs.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b83daafc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\opendbc-master\\opendbc-master-delFalseData\\cadillac_ct6_chassis.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\opendbc-master\\opendbc-master-delFalseData\\cadillac_ct6_object.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\opendbc-master\\opendbc-master-delFalseData\\cadillac_ct6_powertrain.dbc\n",
      "323\n"
     ]
    }
   ],
   "source": [
    "# d1 = {'name': 'revotu', 'age': 24}\n",
    "# d2 = {'age': 25, 'sex': 'male'}\n",
    "# d = {**d1, **d2}\n",
    "cadillac_id_labels = {}\n",
    "for cur_dbc_index in cadillac_dbcs:\n",
    "    cadillac_id_labels.update(get_id_labels(cur_dbc_index)) \n",
    "print(len(cadillac_id_labels))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a35367d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\cadillac_ct6_object.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\cadillac_ct6_powertrain.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\gm_global_a_powertrain.dbc\n"
     ]
    }
   ],
   "source": [
    "# 合并所有Cadillac以及Chevy车的Ground Truth的 0/1 label\n",
    "dict0 = get_id_labels(0)\n",
    "dict1 = get_id_labels(1)\n",
    "dict2 = get_id_labels(2)\n",
    "cadillac_id_labels = dict()\n",
    "for key in dict0.keys() | dict1.keys() | dict2.keys():\n",
    "    for d in (dict0, dict1, dict2):\n",
    "        if d.__contains__(key):\n",
    "            cadillac_id_labels[key] = d[key]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3efd02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_hatchback_ex_2017_can_generated.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_sedan_16_diesel_2019_can_generated.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_touring_2016_can_generated.dbc\n"
     ]
    }
   ],
   "source": [
    "# 合并所有Honda车的Ground Truth的 0/1 label\n",
    "dict3 = get_id_labels(3)\n",
    "dict4 = get_id_labels(4)\n",
    "dict5 = get_id_labels(5)\n",
    "honda_id_labels = dict()\n",
    "for key in dict3.keys() | dict4.keys() | dict5.keys():\n",
    "    for d in (dict3, dict4, dict5):\n",
    "        if d.__contains__(key):\n",
    "            honda_id_labels[key] = d[key]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9ae72d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车的子数据集数据\n",
    "data_hd_1 = pd.read_csv('../Data/Honda/honda001.csv')\n",
    "data_hd_2 = pd.read_csv('../Data/Honda/honda002.csv')\n",
    "data_hd = pd.concat([data_hd_1,data_hd_2])\n",
    "data_hd[\"bin\"] = data_hd[\"Data\"].apply(int, base=16).apply(bin).str[2:].apply(lambda x: x.zfill(64))\n",
    "\n",
    "# 得到Honda车子的数据集的大Trace dict\n",
    "id_tracedict_hd = get_trace(data_hd)\n",
    "\n",
    "# 得到用于训练和测试的id\n",
    "train_ids_hd, test_ids_hd = get_train_test_ids(id_tracedict_hd, honda_id_labels)\n",
    "   \n",
    "# shuffle后得到训练集和测试集，其中训练集的id占70%，测试集的id占30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "25540b4e",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 23.2 MiB for an array with shape (3042808,) and data type int64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-eea259251a4c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mdata_cd_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../Data/Cadillac/CadillacCSV/002.txt.csv'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mdata_cd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata_cd_1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdata_cd_2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdata_cd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"bin\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdata_cd\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"Data\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbin\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# 得到Honda车子的数据集的大Trace dict\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36mapply\u001b[1;34m(self, func, convert_dtype, args, **kwds)\u001b[0m\n\u001b[0;32m   4211\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4212\u001b[0m                 \u001b[0mvalues\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_values\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 4213\u001b[1;33m                 \u001b[0mmapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_infer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconvert\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mconvert_dtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   4214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   4215\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmapped\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSeries\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\lib.pyx\u001b[0m in \u001b[0;36mpandas._libs.lib.maybe_convert_objects\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 23.2 MiB for an array with shape (3042808,) and data type int64"
     ]
    }
   ],
   "source": [
    "# 得到Cadillac车的子数据集数据\n",
    "data_cd_1 = pd.read_csv('../Data/Cadillac/CadillacCSV/001.txt.csv')\n",
    "data_cd_2 = pd.read_csv('../Data/Cadillac/CadillacCSV/002.txt.csv')\n",
    "data_cd = pd.concat([data_cd_1,data_cd_2])\n",
    "data_cd[\"bin\"] = data_cd[\"Data\"].apply(int, base=16).apply(bin).str[2:].apply(lambda x: x.zfill(64))\n",
    "\n",
    "# 得到Honda车子的数据集的大Trace dict\n",
    "id_tracedict_cd = get_trace(data_cd)\n",
    "\n",
    "# 得到用于训练和测试的id\n",
    "train_ids_cd, test_ids_cd = get_train_test_ids(id_tracedict_cd, cadillac_id_labels)\n",
    "   \n",
    "# shuffle后得到训练集和测试集，其中训练集的id占70%，测试集的id占30%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ca86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到honda和caddilac车的trace dict及对应的label dict\n",
    "train_data_dict = {}\n",
    "train_label_dict = {}\n",
    "get_trace_data_dict(train_ids_hd, id_tracedict_hd, honda_id_labels, train_data_dict, train_label_dict)\n",
    "get_trace_data_dict(train_ids_cd, id_tracedict_cd, cadillac_id_labels, train_data_dict, train_label_dict)\n",
    "\n",
    "test_data_dict = {}\n",
    "test_label_dict = {}\n",
    "get_trace_data_dict(test_ids_hd, id_tracedict_hd, honda_id_labels, test_data_dict, test_label_dict)\n",
    "get_trace_data_dict(test_ids_cd, id_tracedict_cd, cadillac_id_labels, test_data_dict, test_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d081b1",
   "metadata": {},
   "source": [
    "## 4.CAN-D数据特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39cefd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_data(id_tracedict_int, all_id_labels): \n",
    "    cur_trace_data = []\n",
    "    cur_trace_label = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        cur_trace = id_tracedict_int[id]\n",
    "        cur_label = all_id_labels[id]\n",
    "        length = len(cur_trace)\n",
    "        start = 4000\n",
    "        end = start + 1000\n",
    "        n = int((length-4000)/1000)\n",
    "        for i in range(n):\n",
    "            cur_trace_data.append(cur_trace[start: end])\n",
    "            cur_trace_label.append(cur_label)\n",
    "            start = end\n",
    "            end = start + 1000\n",
    "    return cur_trace_data, cur_trace_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7e6f91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip\n",
    "def get_bit_Flips(cur_id_traces):\n",
    "    bit_Flips = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_Flips.append(bit_flip)\n",
    "    return bit_Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "41c2fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip的联合概率\n",
    "def get_bit_Flip_LHs(cur_id_traces):\n",
    "    bit_Flip_LHs = []\n",
    "    bit_Flip_LH_nos = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip_LH = np.zeros(64)\n",
    "        bit_flip_LH_no = np.zeros(64)\n",
    "        previous_LH = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(63):\n",
    "                if item[ix] != previous_LH[ix] and item[ix+1] != previous_LH[ix+1]:\n",
    "                    bit_flip_LH[ix] = bit_flip_LH[ix] + 1\n",
    "                if item[ix] == previous_LH[ix] and item[ix+1] == previous_LH[ix+1]:\n",
    "                    bit_flip_LH_no[ix] = bit_flip_LH_no[ix] + 1\n",
    "            previous_LH = item\n",
    "        for ix in range(63):\n",
    "            bit_flip_LH[ix] = bit_flip_LH[ix] / trace_len\n",
    "            bit_flip_LH_no[ix] = bit_flip_LH_no[ix] / trace_len\n",
    "\n",
    "        bit_flip_LH = np.append(bit_flip_LH, 0)\n",
    "        bit_flip_LH = np.append(bit_flip_LH, 0)\n",
    "        bit_flip_LH_no = np.append(bit_flip_LH_no, 0)\n",
    "        bit_flip_LH_no = np.append(bit_flip_LH_no, 0)\n",
    "\n",
    "        bit_Flip_LHs.append(bit_flip_LH)\n",
    "        bit_Flip_LH_nos.append(bit_flip_LH_no)\n",
    "    return bit_Flip_LHs, bit_Flip_LH_nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cdb2cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_id_tracelist 通过大端bit序列得到小端bit序列\n",
    "def get_reverse_id_traces(cur_id_traces):\n",
    "    reverse_id_traces = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        id_tracelist = cur_id_traces[i]\n",
    "        reverse_id_tracelist = []\n",
    "        for item in id_tracelist:\n",
    "            cur_tracelist = [0,1,2,3,4,5,6,7]\n",
    "            cur_temp = []\n",
    "            count = 7\n",
    "            for i in range(64):\n",
    "                cur_temp.append(item[i])\n",
    "                if (i+1)%8 == 0:\n",
    "                    cur_tracelist[count] = cur_temp\n",
    "                    count = count - 1\n",
    "                    cur_temp = []\n",
    "            reverse_id_tracelist.append(np.concatenate(cur_tracelist).tolist())\n",
    "        reverse_id_traces[i] = reverse_id_tracelist\n",
    "    return reverse_id_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6e8adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到每个bit的15个特征\n",
    "def get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i):\n",
    "    f1 = bit_Flips[i][ix]\n",
    "    f2 = bit_Flips_LH[i][ix] / bit_Flips[i][ix+1]\n",
    "    f3 = bit_Flips_LH[i][ix] / bit_Flips[i][ix]\n",
    "    f4 = bit_Flip_LH_nos[i][ix] / (1 - bit_Flips[i][ix+1])\n",
    "    f5 = bit_Flip_LH_nos[i][ix] / (1 - bit_Flips[i][ix])\n",
    "    return np.array([f1,f2,f3,f4,f5])\n",
    "\n",
    "def get_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i):\n",
    "    cur_bit_feature = []\n",
    "    feature_sub1 = get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i)\n",
    "    feature_sub2 = get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix+1, i)\n",
    "    feature_sub3 = feature_sub2 - feature_sub1\n",
    "    return np.concatenate((feature_sub1,feature_sub2,feature_sub3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6606d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个bit赋予15个特征\n",
    "def get_bit_features_list(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos):\n",
    "    bit_features_list = []\n",
    "    for i in range(len(bit_Flips)):\n",
    "        bit_features = []\n",
    "        for ix in range(64):\n",
    "            bit_features.append(get_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i))\n",
    "        bit_features_list.append(bit_features)\n",
    "    return bit_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a6a3d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小端转成大端的正常格式，方便与上边生成的ground truth label匹配\n",
    "def LE_to_BE(reverse_bit_features_list):\n",
    "    bit_features_list = []\n",
    "    for i in range(len(reverse_bit_features_list)):\n",
    "        item = reverse_bit_features_dict[i]\n",
    "        cur_bit_features = [0,1,2,3,4,5,6,7]\n",
    "        cur_temp = []\n",
    "        count = 7\n",
    "        for i in range(64):\n",
    "            cur_temp.append(item[i])\n",
    "            if (i+1)%8 == 0:\n",
    "                cur_bit_features[count] = cur_temp\n",
    "                count = count - 1\n",
    "                cur_temp = []\n",
    "        bit_features_list.append(np.concatenate(cur_bit_features).tolist())\n",
    "    return bit_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "110be394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Trace与Ground Truth都存在的id\n",
    "def get_all_datas_labels(bit_features_list, cur_id_labels):\n",
    "    alldatas = []\n",
    "    alllabels = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for i in range(64):\n",
    "            alldatas.append(cur_features[i])\n",
    "            alllabels.append(int(cur_labels[i]))\n",
    "    return alldatas, alllabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "05836d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffle_data_label(cur_trace_data, cur_trace_label):\n",
    "    trace_indexs = pd.DataFrame(cur_trace_label).index.tolist()\n",
    "    random.shuffle(trace_indexs)\n",
    "    trace_data, trace_labels = np.array(cur_trace_data)[trace_indexs], np.array(cur_trace_label)[trace_indexs]\n",
    "    return trace_data, trace_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f583f",
   "metadata": {},
   "source": [
    "## 5.训练大端的RF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e9c690",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_id_traces, train_id_labels = get_trace_data(train_data_dict, train_label_dict)\n",
    "bit_Flips_train = get_bit_Flips(train_id_traces)\n",
    "bit_Flip_LHs_train, bit_Flip_LH_nos_train = get_bit_Flip_LHs(train_id_traces)\n",
    "bit_features_list_train = get_bit_features_list(bit_Flips_train, bit_Flip_LHs_train, bit_Flip_LH_nos_train)\n",
    "traindatas_msb, trainlabels_msb = get_all_datas_labels(bit_features_list_train, train_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f6d1f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id_traces, test_id_labels = get_trace_data(test_data_dict, test_label_dict)\n",
    "bit_Flips_test = get_bit_Flips(test_id_traces)\n",
    "bit_Flip_LHs_test, bit_Flip_LH_nos_test = get_bit_Flip_LHs(test_id_traces)\n",
    "bit_features_list_test = get_bit_features_list(bit_Flips_test, bit_Flip_LHs_test, bit_Flip_LH_nos_test)\n",
    "testdatas_msb, testlabels_msb = get_all_datas_labels(bit_features_list_test, test_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b3f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_msb, trainlabels_msb = get_shuffle_data_label(traindatas_msb, trainlabels_msb)\n",
    "testdatas_msb, testlabels_msb = get_shuffle_data_label(testdatas_msb, testlabels_msb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f255541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traindata_msb = pd.DataFrame(traindatas_msb)\n",
    "Traindata_msb['label'] = np.array(trainlabels_msb)\n",
    "Traindata_msb = Traindata_msb.fillna(0)\n",
    "traindatas_msb = np.array(Traindata_msb.iloc[:,:15])\n",
    "trainlabels_msb = np.array(Traindata_msb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82ee54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata_msb = pd.DataFrame(testdatas_msb)\n",
    "Testdata_msb['label'] = np.array(testlabels_msb)\n",
    "Testdata_msb = Testdata_msb.fillna(0)\n",
    "testdatas_msb = np.array(Testdata_msb.iloc[:,:15])\n",
    "testlabels_msb = np.array(Testdata_msb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f06bd9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#随机森林方法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "model_msb = RandomForestClassifier(n_estimators= 30)\n",
    "model_msb.fit(traindatas_msb, trainlabels_msb)\n",
    "\n",
    "print(\"训练集:\")\n",
    "predict_target_msb = model_msb.predict(traindatas_msb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb == trainlabels_msb),len(trainlabels_msb))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_msb,predict_target_msb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb,predict_target_msb))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_msb =model_msb.predict(testdatas_msb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb == testlabels_msb),len(testlabels_msb))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_msb,predict_target_test_msb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb,predict_target_test_msb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "f2c79a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model/CAN-D_FR_MSB.model']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# RF大端模型保存\n",
    "joblib.dump(filename='./Model/CAN-D_FR_MSB.model', value=model_msb)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4adcf",
   "metadata": {},
   "source": [
    "## 训练小端的RF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11dfd71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "reverse_train_data_dict = get_reverse_id_tracedict(train_data_dict)\n",
    "reverse_bit_flip_dict_train = get_bit_flip_dict(reverse_train_data_dict)\n",
    "reverse_bit_flip_LH_dict_train, reverse_bit_flip_LH_no_dict_train = get_bit_flip_LH_dict(reverse_train_data_dict)\n",
    "reverse_bit_features_dict_train = get_bit_features_dict(reverse_bit_flip_dict_train, reverse_bit_flip_LH_dict_train, reverse_bit_flip_LH_no_dict_train)\n",
    "bit_features_dict_train_lsb = LE_to_BE(reverse_bit_features_dict_train)\n",
    "traindatas_lsb, trainlabels_lsb = get_all_datas_labels(bit_features_dict_train_lsb, train_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cf86408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "reverse_test_data_dict = get_reverse_id_tracedict(test_data_dict)\n",
    "reverse_bit_flip_dict_test = get_bit_flip_dict(reverse_test_data_dict)\n",
    "reverse_bit_flip_LH_dict_test, reverse_bit_flip_LH_no_dict_test = get_bit_flip_LH_dict(reverse_test_data_dict)\n",
    "reverse_bit_features_dict_test = get_bit_features_dict(reverse_bit_flip_dict_test, reverse_bit_flip_LH_dict_test, reverse_bit_flip_LH_no_dict_test)\n",
    "bit_features_dict_test_lsb = LE_to_BE(reverse_bit_features_dict_test)\n",
    "testdatas_lsb, testlabels_lsb = get_all_datas_labels(bit_features_dict_test_lsb, test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0150d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_lsb, trainlabels_lsb = get_shuffle_data_label(traindatas_lsb, trainlabels_lsb)\n",
    "testdatas_lsb, testlabels_lsb = get_shuffle_data_label(testdatas_lsb, testlabels_lsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c11316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traindata_lsb = pd.DataFrame(traindatas_lsb)\n",
    "Traindata_lsb['label'] = np.array(trainlabels_lsb)\n",
    "Traindata_lsb = Traindata_lsb.fillna(0)\n",
    "traindatas_lsb = np.array(Traindata_lsb.iloc[:,:15])\n",
    "trainlabels_lsb = np.array(Traindata_lsb.iloc[:,-1])\n",
    "\n",
    "Testdata_lsb = pd.DataFrame(testdatas_lsb)\n",
    "Testdata_lsb['label'] = np.array(testlabels_lsb)\n",
    "Testdata_lsb = Testdata_lsb.fillna(0)\n",
    "testdatas_lsb = np.array(Testdata_lsb.iloc[:,:15])\n",
    "testlabels_lsb = np.array(Testdata_lsb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c13e221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "2717 2944\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2644\n",
      "           1       0.95      0.26      0.40       300\n",
      "\n",
      "    accuracy                           0.92      2944\n",
      "   macro avg       0.94      0.63      0.68      2944\n",
      "weighted avg       0.93      0.92      0.90      2944\n",
      "\n",
      "混淆矩阵：\n",
      "[[2640    4]\n",
      " [ 223   77]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "1138 1280\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1142\n",
      "           1       0.43      0.09      0.14       138\n",
      "\n",
      "    accuracy                           0.89      1280\n",
      "   macro avg       0.66      0.54      0.54      1280\n",
      "weighted avg       0.85      0.89      0.85      1280\n",
      "\n",
      "混淆矩阵：\n",
      "[[1126   16]\n",
      " [ 126   12]]\n"
     ]
    }
   ],
   "source": [
    "#随机森林方法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "model_lsb = RandomForestClassifier(n_estimators= 30)\n",
    "model_lsb.fit(traindatas_lsb, trainlabels_lsb)\n",
    "\n",
    "print(\"训练集:\")\n",
    "predict_target_lsb = model_lsb.predict(traindatas_lsb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_lsb == trainlabels_lsb), len(trainlabels_lsb))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_lsb, predict_target_lsb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_lsb, predict_target_lsb))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_lsb = model_lsb.predict(testdatas_lsb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_lsb == testlabels_lsb),len(testlabels_lsb))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_lsb, predict_target_test_lsb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_lsb, predict_target_test_lsb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c31dee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model/CAN-D_FR_LSB.model']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF大端模型保存\n",
    "joblib.dump(filename='./Model/CAN-D_FR_LSB.model', value=model_lsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10724fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = []\n",
    "setlist1 = ['JB', 'C']\n",
    "setlist2 = ['JB', 'JL', 'C']\n",
    "setlist3 = ['JL', 'C']\n",
    "flag = True\n",
    "count = 0\n",
    "for a in setlist1:\n",
    "    for b in setlist2:\n",
    "        for c in setlist2:\n",
    "            for d in setlist2:\n",
    "                for e in setlist2:\n",
    "                    for f in setlist2:\n",
    "                        for g in setlist2:\n",
    "                            for h in setlist3:\n",
    "                                v = [a,b,c,d,e,f,g,h]\n",
    "                                for i in range(8):\n",
    "                                    if(v[i] == 'JB' and v[i+1] == 'JL'):\n",
    "                                        flag = False\n",
    "                                        break\n",
    "                                    if(v[i] == 'JB' and i<6 and v[i+2] == 'JL'):\n",
    "                                        flag = False\n",
    "                                        break\n",
    "                                if flag == True:\n",
    "                                    V.append(v)\n",
    "                                    count = count + 1\n",
    "                                flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d02dda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for v in V:\n",
    "    e = ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "    for i in range(8):\n",
    "        if v[i] == 'JB':\n",
    "            e[i] = 'B'\n",
    "            e[i+1] = 'B'\n",
    "        if v[i] == 'JL':\n",
    "            e[i] = 'L'\n",
    "            e[i-1] = 'L'\n",
    "    E.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d2e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "EB = pd.DataFrame(E).replace('C', 'B')\n",
    "EB = np.array(EB).tolist()\n",
    "\n",
    "EL = pd.DataFrame(E).replace('C', 'L')\n",
    "EL = np.array(EL).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a307fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到所有可能的信号标记集合T\n",
    "def get_T(proba_msb, proba_lsb):\n",
    "    T = []\n",
    "    for e in EB:\n",
    "        t = []\n",
    "        for i in range(8):\n",
    "            if e[i] == 'B':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_msb[j])\n",
    "            if e[i] == 'L':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_lsb[j])\n",
    "        T.append(t)\n",
    "    for e in EL:\n",
    "        t = []\n",
    "        for i in range(8):\n",
    "            if e[i] == 'B':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_msb[j])\n",
    "            if e[i] == 'L':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_lsb[j])\n",
    "        T.append(t)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4d51985",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_msb_dict = {}\n",
    "for id in bit_features_dict_test.keys():\n",
    "    cur_predictproba_msb = []\n",
    "    temp = pd.DataFrame(bit_features_dict_test[id]).fillna(0)\n",
    "    cur_predict_proba_msb = model_msb.predict_proba(temp)\n",
    "    for prediction in cur_predict_proba_msb:\n",
    "        cur_predictproba_msb.append(prediction[1])\n",
    "    predict_proba_msb_dict[id] = cur_predictproba_msb\n",
    "    \n",
    "predict_proba_lsb_dict = {}\n",
    "for id in bit_features_dict_test_lsb.keys():\n",
    "    cur_predictproba_lsb = []\n",
    "    temp = pd.DataFrame(bit_features_dict_test_lsb[id]).fillna(0)\n",
    "    cur_predict_proba_lsb = model_lsb.predict_proba(temp)\n",
    "    for prediction in cur_predict_proba_lsb:\n",
    "        cur_predictproba_lsb.append(prediction[1])\n",
    "    predict_proba_lsb_dict[id] = cur_predictproba_lsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8584235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 0.6\n",
    "final_label_dict = {}\n",
    "for id in predict_proba_msb_dict.keys():\n",
    "    curT = get_T(predict_proba_msb_dict[id], predict_proba_lsb_dict[id])\n",
    "    mint0 = []\n",
    "    for t in curT:\n",
    "        t0 = 0\n",
    "        for f in t:\n",
    "            t0 = t0 + min(f, B)\n",
    "        mint0.append(t0)\n",
    "    tf = pd.DataFrame(curT)\n",
    "    tf['t0'] = mint0\n",
    "    res = tf[tf['t0'] == min(mint0)]\n",
    "    final_res = res.drop_duplicates()\n",
    "    final_t = np.array(final_res)[0][:-1]\n",
    "    final_label = []\n",
    "    for i in range(64):\n",
    "        if final_t[i] >= B:\n",
    "            final_label.append(i)\n",
    "    final_label_dict[id] = final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db706ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_locate_dict = {}\n",
    "for id in test_label_dict.keys():\n",
    "    temp_list = test_label_dict[id]\n",
    "    cur_label = []\n",
    "    for i in range(64):\n",
    "        if(temp_list[i] == 1):\n",
    "            cur_label.append(i)\n",
    "    test_label_locate_dict[id] = cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ee35869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 63]\n",
      "[7, 31, 32, 33, 38, 39, 49, 50, 55, 59, 63]\n",
      "------------------------------------------\n",
      "[59]\n",
      "[15, 23, 31, 47, 49, 59, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[40, 41, 42, 49, 51, 59, 63]\n",
      "------------------------------------------\n",
      "[31, 59]\n",
      "[15, 31, 59, 63]\n",
      "------------------------------------------\n",
      "[63]\n",
      "[15, 27, 41, 42, 59, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[]\n",
      "------------------------------------------\n",
      "[]\n",
      "[63]\n",
      "------------------------------------------\n",
      "[39]\n",
      "[15, 31]\n",
      "------------------------------------------\n",
      "[]\n",
      "[5, 6, 7, 14, 23, 50, 52, 63]\n",
      "------------------------------------------\n",
      "[48]\n",
      "[31, 32, 34, 47]\n",
      "------------------------------------------\n",
      "[15]\n",
      "[55]\n",
      "------------------------------------------\n",
      "[]\n",
      "[3, 4, 15, 31]\n",
      "------------------------------------------\n",
      "[]\n",
      "[55]\n",
      "------------------------------------------\n",
      "[]\n",
      "[23, 39]\n",
      "------------------------------------------\n",
      "[23, 52]\n",
      "[0, 1, 3, 4, 23, 31, 52, 63]\n",
      "------------------------------------------\n",
      "[59]\n",
      "[16, 17, 43]\n",
      "------------------------------------------\n",
      "[]\n",
      "[0, 31, 33, 47]\n",
      "------------------------------------------\n",
      "[]\n",
      "[47]\n",
      "------------------------------------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[63]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for id in final_label_dict.keys():\n",
    "    print(final_label_dict[id])\n",
    "    print(test_label_locate_dict[id])\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7048df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_label_dict = {}\n",
    "for id in final_label_dict.keys():\n",
    "    cur_label = np.zeros(64)\n",
    "    for location in final_label_dict[id]:\n",
    "        cur_label[location] = 1\n",
    "    res_test_label_dict[id] = cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "482c60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flatten_array(label_dict):\n",
    "    flatten_list = []\n",
    "    for id in label_dict.keys():\n",
    "        bitlist = label_dict[id]\n",
    "        for i in range(64):\n",
    "            flatten_list.append(bitlist[i])\n",
    "    return np.array(flatten_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f915857",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_flatten_array(res_test_label_dict)\n",
    "labels = get_flatten_array(test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7797d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测正确数量,训练集样本量:\n",
      "1146 1280\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.94      1142\n",
      "         1.0       0.67      0.06      0.11       138\n",
      "\n",
      "    accuracy                           0.90      1280\n",
      "   macro avg       0.78      0.53      0.53      1280\n",
      "weighted avg       0.87      0.90      0.85      1280\n",
      "\n",
      "混淆矩阵：\n",
      "[[1138    4]\n",
      " [ 130    8]]\n"
     ]
    }
   ],
   "source": [
    "# 每个bit是否识别正确的准确度统计\n",
    "\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(res == labels),len(labels))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(labels,res))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(labels,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b88666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsb边界是否识别正确的准确度统计\n",
    "\n",
    "right_count = 0\n",
    "total_count = 0\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i] == 1):\n",
    "        total_count = total_count + 1\n",
    "        if(res[i] == 1):\n",
    "            right_count = right_count + 1\n",
    "acc = right_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69a409e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057971014492753624"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Commonl_Py3.6]",
   "language": "python",
   "name": "conda-env-Commonl_Py3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
