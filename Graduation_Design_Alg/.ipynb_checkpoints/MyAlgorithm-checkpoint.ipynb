{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff9e374",
   "metadata": {},
   "source": [
    "## 1.提取DBC文件信息转为数据域分割的GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0c519c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "node = []\n",
    "allDatas = []\n",
    "siganlList = []\n",
    "SignalsName = []\n",
    "messageName = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0fcc02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file_name):\n",
    "    global node,allDatas,siganlList,SignalsName,messageName\n",
    "    ''' 得到dbc文件的绝对路径'''\n",
    "    filePath = file_name\n",
    "    if filePath:\n",
    "        print(filePath)\n",
    "        f = open(filePath, \"r\")  # 设置文件对象\n",
    "    else:\n",
    "        print(\"读取文件失败！\")\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    NodesPattern:节点\n",
    "    MessagePattern：消息\n",
    "    SignalPattern：信号\n",
    "    \"\"\"\n",
    "    NodesPattern = re.compile(r\"BU_: (.*)\", re.S)\n",
    "    MessagePattern = re.compile(r\"BO_ (.*?) (.*?): (.*?) (.*)\", re.S)\n",
    "#     SignalPattern = re.compile('''SG_ (.*?) : (.*?)\\|(.*?)@.*? \\((.*?),(.*?)\\) \\[(.*?)\\|(.*?)\\] \"(.*?)\" (.*)''', re.S)\n",
    "    SignalPattern = re.compile('''SG_ (.*?) : (.*?)\\|(.*?)@([0-9])([+|-]) \\((.*?),(.*?)\\) \\[(.*?)\\|(.*?)\\] \"(.*?)\" (.*)''', re.S)\n",
    "    DefaultValue = '''BA_ \"GenSig(.*?)\" SG_ (\\d+) signalname (\\d+);'''\n",
    "\n",
    "    line = f.readline()\n",
    "    allDatas=[]\n",
    "    while line:\n",
    "        \"\"\" 匹配出节点 \"\"\"\n",
    "        NodesSearched = re.search(NodesPattern, line.strip())\n",
    "        if NodesSearched:\n",
    "            node = NodesSearched.group(1).split(\" \")\n",
    "            #print(node)\n",
    "        \"\"\" 匹配出消息 \"\"\"\n",
    "        MessageSearched = re.search(MessagePattern, line.strip())\n",
    "        if MessageSearched:\n",
    "            siganlList.clear()\n",
    "            \"\"\"如果匹配到了message，则获取到message的相关参数 \n",
    "             比如匹配到了NM_Message_ESC_409，则会解析出改message的一些参数构成list对象['1033', 'NM_Message_ESC_409', '8', 'ESC']\n",
    "             这四个参数分别是 messgage ID ;message name ; messgae dataLenth ,message sender\n",
    "             而且把这个list对象 加在了 siganlList 索引0的位置\n",
    "            \"\"\"\n",
    "            Message = list(MessageSearched.groups())\n",
    "            siganlList.append(Message)\n",
    "            \"\"\" 只 要 message的名字 messageName 列表中\"\"\"\n",
    "            messageName.append(Message[1])\n",
    "            \"\"\"读取下一行\"\"\"\n",
    "            line = f.readline()\n",
    "            \"\"\"因为有些message并没有定义signal，所以 下一行还是message\"\"\"\n",
    "            MessageSearched = re.search(MessagePattern, line.strip())\n",
    "            SignalSearched = re.search(SignalPattern, line.strip())\n",
    "            \"\"\"下一行如果不是message的内容 就一定是signal的内容了\"\"\"\n",
    "            if not MessageSearched:\n",
    "                while SignalSearched:\n",
    "                    \"\"\"获取信号的参数追加到siganlList\"\"\"\n",
    "                    signal = list(SignalSearched.groups())\n",
    "                    siganlList.append(signal)\n",
    "                    \"\"\"只获取 signal name\"\"\"\n",
    "                    SignalsName.append(signal[0])\n",
    "\n",
    "                    # 再次解析信号，直到这个message下的信号全部解析完毕\n",
    "                    line = f.readline()\n",
    "                    SignalSearched = re.search(SignalPattern, line.strip())\n",
    "           # print(siganlList)\n",
    "            c = copy.deepcopy(siganlList)\n",
    "            allDatas.append(c)\n",
    "        else:\n",
    "            line = f.readline()\n",
    "            MessageSearched = re.search(MessagePattern, line.strip())\n",
    "    f.close()  # 将文件关闭\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a5ae5975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\cadillac_ct6_object.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\cadillac_ct6_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\gm_global_a_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\honda_civic_hatchback_ex_2017_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\honda_civic_sedan_16_diesel_2019_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\honda_civic_touring_2016_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\tesla_can.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\tesla_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\tesla_radar.dbc']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_names = []\n",
    "path = os.path.abspath('../My_DBC')\n",
    "# path = os.path.abspath('../opendbc-master/opendbc-master-delFalseData')\n",
    "# path = os.path.abspath('./opendbc-master/opendbc-master')\n",
    "dirs = os.listdir(path)                    # 获取指定路径下的文件\n",
    "for i in dirs:\n",
    "    if os.path.splitext(i)[1] == \".dbc\":\n",
    "        file_names.append(os.path.join(path,i))\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583de4e",
   "metadata": {},
   "source": [
    "## 2.处理原始bit数据和GroundTruth数据的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "702784f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_labels(index):\n",
    "    file_name = file_names[index]\n",
    "    readFile(file_name)\n",
    "\n",
    "    # 将DBC文件中的ID(10进制数)改为ID(16进制数)\n",
    "    data_gts = {}\n",
    "    for alldata in allDatas:\n",
    "        data_gts[str(hex(int(alldata[0][0])))[2:]] = alldata\n",
    "\n",
    "    # 得到DBC文件中各ID Message对应信号位置\n",
    "    all_id_lsbs = {}\n",
    "    for k in data_gts.keys():\n",
    "        message = data_gts[k]\n",
    "        lsb_list = []\n",
    "        series = np.zeros(64)\n",
    "        message_id = message[0][0]+\"_\"+message[0][1]\n",
    "        del message[0]\n",
    "        for signal in message:\n",
    "            start = int(signal[1])\n",
    "            length = int(signal[2])\n",
    "            endianness = int(signal[3])\n",
    "            start_row = int(start / 8)\n",
    "            start_col = 8 - (start - start_row * 8) - 1\n",
    "            new_start = start_row * 8 + start_col\n",
    "            if endianness == 0:\n",
    "                new_end = new_start + length\n",
    "                cur_lsb = new_end - 1\n",
    "            if endianness == 1:\n",
    "                cur_lsb = new_start\n",
    "            lsb_list.append(cur_lsb)\n",
    "        all_id_lsbs[k] = lsb_list\n",
    "\n",
    "    # 将各ID Message的信号位置改为 0/1 label\n",
    "    all_id_labels = {}\n",
    "    for k in all_id_lsbs:\n",
    "        cur_lsb_list = all_id_lsbs[k]\n",
    "        cur_label = np.zeros(64)\n",
    "        for cur_lsb in cur_lsb_list:\n",
    "            cur_label[cur_lsb] = 1\n",
    "        all_id_labels[k] = cur_label\n",
    "    return all_id_lsbs, all_id_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "63ba49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(id_tracedict_int, all_id_labels):\n",
    "    ids = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        if(id_tracedict_int.__contains__(id) and all_id_labels.__contains__(id)):\n",
    "            ids.append(id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6bad01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(data):\n",
    "    group = data.groupby(by=\"ID\")\n",
    "    id_tracedict = {}\n",
    "    for trace in list(group):\n",
    "        id_tracedict[trace[0]] = trace[1][\"bin\"].apply(lambda x: list(x)).apply(lambda x: list(map(int, x))).tolist()\n",
    "    return id_tracedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b62034f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 设置全局的随机种子\n",
    "random.seed(100)\n",
    "# 以id为单位shuffle\n",
    "# def get_train_test_ids(id_tracedict, all_id_labels):\n",
    "#     ids = get_ids(id_tracedict, all_id_labels)\n",
    "# #     random.shuffle(ids)\n",
    "#     ids.sort()\n",
    "#     train_len = int(len(ids)*0.7)\n",
    "#     train_ids = ids[:train_len]\n",
    "#     test_ids = ids[train_len:]\n",
    "#     return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "110411d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_data_dict(cur_ids, id_tracedict_int, all_id_labels, trace_data_dict, trace_label_dict): \n",
    "    for id in cur_ids:\n",
    "        trace_data_dict[id] = id_tracedict_int[id]\n",
    "        trace_label_dict[id] = all_id_labels[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8633add5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpad_0(cur_str, width):\n",
    "    pad_len = width - len(cur_str)\n",
    "    for i in range(pad_len):\n",
    "        cur_str = cur_str + '0'\n",
    "    return cur_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fd7cd",
   "metadata": {},
   "source": [
    "## 3.综合Honda和Cadillac数据，得到训练集和测试集（包括0/1Label）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c577f",
   "metadata": {},
   "source": [
    "#### 得到label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a5fc9282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_hatchback_ex_2017_can_generated.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_sedan_16_diesel_2019_can_generated.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_touring_2016_can_generated.dbc\n"
     ]
    }
   ],
   "source": [
    "# 合并所有Honda车的Ground Truth的 0/1 label\n",
    "all_id_lsbs3, dict3 = get_id_labels(3)\n",
    "all_id_lsbs4, dict4 = get_id_labels(4)\n",
    "all_id_lsbs5, dict5 = get_id_labels(5)\n",
    "honda_id_labels = dict()\n",
    "for key in dict3.keys() | dict4.keys() | dict5.keys():\n",
    "    for d in (dict3, dict4, dict5):\n",
    "        if d.__contains__(key):\n",
    "            honda_id_labels[key] = d[key]\n",
    "            break\n",
    "honda_id_lsb = dict()\n",
    "for key in all_id_lsbs3.keys() | all_id_lsbs4.keys() | all_id_lsbs5.keys():\n",
    "    for d in (all_id_lsbs3, all_id_lsbs4, all_id_lsbs5):\n",
    "        if d.__contains__(key):\n",
    "            honda_id_lsb[key] = d[key]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5c9a22fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\cadillac_ct6_object.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\cadillac_ct6_powertrain.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\gm_global_a_powertrain.dbc\n"
     ]
    }
   ],
   "source": [
    "# 合并所有Cadillac以及Chevy车的Ground Truth的 0/1 label\n",
    "all_id_lsbs0, dict0 = get_id_labels(0)\n",
    "all_id_lsbs1, dict1 = get_id_labels(1)\n",
    "all_id_lsbs2, dict2 = get_id_labels(2)\n",
    "cadillac_id_labels = dict()\n",
    "for key in dict0.keys() | dict1.keys() | dict2.keys():\n",
    "    for d in (dict0, dict1, dict2):\n",
    "        if d.__contains__(key):\n",
    "            cadillac_id_labels[key] = d[key]\n",
    "            break\n",
    "cadillac_id_lsb = dict()\n",
    "for key in all_id_lsbs0.keys() | all_id_lsbs1.keys() | all_id_lsbs2.keys():\n",
    "    for d in (all_id_lsbs0, all_id_lsbs1, all_id_lsbs2):\n",
    "        if d.__contains__(key):\n",
    "            cadillac_id_lsb[key] = d[key]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6eb70311",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct2bin = {\"0\":\"0000\",\"1\":\"0001\",\"2\":\"0010\",\"3\":\"0011\",\"4\":\"0100\",\"5\":\"0101\",\"6\":\"0110\",\"7\":\"0111\",\"8\":\"1000\",\"9\":\"1001\",\n",
    "           \"a\":\"1010\",\"b\":\"1011\",\"c\":\"1100\",\"d\":\"1101\",\"e\":\"1110\",\"f\":\"1111\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "853c26cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2bin(cur_hex):\n",
    "    res = \"\"\n",
    "    for i in cur_hex:\n",
    "        res = res + oct2bin[i]\n",
    "    res = rpad_0(res,64)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52ab46a7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plt_data_flip_dict(train_data_dict, train_label_dict):\n",
    "    for id in train_data_dict.keys():\n",
    "        messagelist = train_data_dict[id]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "    #     print(\"--------------------------------------------------------------------------------------------------------\")\n",
    "    #     print(id+\": \")\n",
    "        fig = plt.figure(figsize=(8,3))\n",
    "        plt.bar(np.arange(64),bit_flip)\n",
    "        plt.bar(np.arange(64),train_label_dict[id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a095b1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data_label_dict(true_train_ids, train_data_dict,train_label_dict):\n",
    "    new_train_data_dict = {}\n",
    "    new_train_label_dict = {}\n",
    "    for i in range(len(train_data_dict)):\n",
    "        if i in true_train_ids:\n",
    "            id = list(train_data_dict.keys())[i]\n",
    "            new_train_data_dict[id] = train_data_dict[id]\n",
    "            new_train_label_dict[id] = train_label_dict[id]\n",
    "    return new_train_data_dict, new_train_label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ad19b1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_ids(true_train_ids, train_data_dict):\n",
    "    true_ids = []\n",
    "    for i in range(len(train_data_dict)):\n",
    "        if i in true_train_ids:\n",
    "            id = list(train_data_dict.keys())[i]\n",
    "            true_ids.append(id)\n",
    "    return true_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "39cefd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_data(id_tracedict_int, all_id_labels): \n",
    "    cur_trace_data = []\n",
    "    cur_trace_label = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        cur_trace = id_tracedict_int[id]\n",
    "        cur_label = all_id_labels[id]\n",
    "        length = len(cur_trace)\n",
    "        start = 4000\n",
    "        end = start + 1000\n",
    "        n = int((length-4000)/1000)\n",
    "        for i in range(n):\n",
    "            cur_trace_data.append(cur_trace[start: end])\n",
    "            cur_trace_label.append(cur_label)\n",
    "            start = end\n",
    "            end = start + 1000\n",
    "    return cur_trace_data, cur_trace_label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f4c775",
   "metadata": {},
   "source": [
    "#### honda数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9ae72d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车的子数据集数据\n",
    "data_hd = pd.read_csv('../Data/Honda_process_bin/honda001.csv')\n",
    "# data_hd_1 = pd.read_csv('../Data/Honda_process_bin/honda001.csv')\n",
    "# data_hd_2 = pd.read_csv('../Data/Honda_process_bin/honda002.csv')\n",
    "# data_hd = pd.concat([data_hd_1,data_hd_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2f178ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车子的数据集的大Trace dict\n",
    "id_tracedict_hd = get_trace(data_hd)\n",
    "honda_ids = get_ids(id_tracedict_hd, honda_id_labels)\n",
    "honda_data_dict = {}\n",
    "honda_label_dict = {}\n",
    "get_trace_data_dict(honda_ids, id_tracedict_hd, honda_id_labels, honda_data_dict, honda_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "49f5b873",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_honda_ids = [1,6,7,10,12, 13]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4405a65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['158', '1d0', '1ea', '255', '309', '324']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_honda_idname = get_true_ids(true_honda_ids, honda_data_dict)\n",
    "true_honda_idname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a1fe3497",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_honda_data_dict, new_honda_label_dict = clear_data_label_dict(true_honda_ids, honda_data_dict, honda_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e87c2fdb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# plt_data_flip_dict(new_honda_data_dict, new_honda_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "13e94bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "honda_trace_data, honda_trace_label = get_trace_data(new_honda_data_dict, new_honda_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8048476d",
   "metadata": {},
   "source": [
    "#### cadillac数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "25540b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Cadillac车的子数据集数据\n",
    "data_cd = pd.read_csv('../Data/Cadillac_process_bin/001.txt.csv')\n",
    "# data_cd_1 = pd.read_csv('../Data/Cadillac_process_bin/001.txt.csv')\n",
    "# data_cd_2 = pd.read_csv('../Data/Cadillac_process_bin/002.txt.csv')\n",
    "# data_cd = pd.concat([data_cd_1,data_cd_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "12719425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车子的数据集的大Trace dict\n",
    "id_tracedict_cd = get_trace(data_cd)\n",
    "cadillac_ids = get_ids(id_tracedict_cd, cadillac_id_labels)\n",
    "cadillac_data_dict = {}\n",
    "cadillac_label_dict = {}\n",
    "get_trace_data_dict(cadillac_ids, id_tracedict_cd, cadillac_id_labels, cadillac_data_dict, cadillac_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bb999f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_cadillac_ids = [8,9,10,11,15,19,21,26,27]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "55352c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17d', '180', '184', '1a1', '1e5', '260', '262', '348', '34a']"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_cadillac_idname = get_true_ids(true_cadillac_ids, cadillac_data_dict)\n",
    "true_cadillac_idname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b05be3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_cadillac_data_dict, new_cadillac_label_dict = clear_data_label_dict(true_cadillac_ids, cadillac_data_dict, cadillac_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4784e56",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# plt_data_flip_dict(cadillac_data_dict, cadillac_label_dict)\n",
    "# plt_data_flip_dict(new_cadillac_data_dict, new_cadillac_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd0181e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "cadillac_trace_data, cadillac_trace_label = get_trace_data(new_cadillac_data_dict, new_cadillac_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0586f5f",
   "metadata": {},
   "source": [
    "#### chevy数据集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "180743fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Chevy车的子数据集数据\n",
    "data_ch = pd.read_csv('../Data/Chevy_process_bin/chevy001.csv')\n",
    "# data_ch_2 = pd.read_csv('../Data/Chevy_process_bin/chevy002.csv')\n",
    "# data_ch = pd.concat([data_ch_1,data_ch_2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2e24cd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "id_tracedict_ch = get_trace(data_ch)\n",
    "chevy_ids = get_ids(id_tracedict_ch, cadillac_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bf5e048c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chevy_data_dict = {}\n",
    "chevy_label_dict = {}\n",
    "get_trace_data_dict(chevy_ids, id_tracedict_ch, cadillac_id_labels, chevy_data_dict, chevy_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b8da496",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_chevy_ids = [6,7,13,14,15,28]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f2f9fa0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['17d', '1a1', '32a', '348', '34a', 'be']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_chevy_idname = get_true_ids(true_chevy_ids, chevy_data_dict)\n",
    "true_chevy_idname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "adbc422a",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_checy_data_dict, new_chevy_label_dict = clear_data_label_dict(true_chevy_ids, chevy_data_dict, chevy_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "8911a94a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt_data_flip_dict(chevy_data_dict, chevy_label_dict)\n",
    "# plt_data_flip_dict(new_checy_data_dict, new_chevy_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "55dbbcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chevy_trace_data, chevy_trace_label = get_trace_data(new_checy_data_dict, new_chevy_label_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8a4e74d",
   "metadata": {},
   "source": [
    "#### 得到训练集和测试集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2c1ec6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label(id_tracedict_int, all_id_labels):\n",
    "    cur_trace_data, cur_trace_label = get_trace_data(id_tracedict_int, all_id_labels)\n",
    "    trace_indexs = pd.DataFrame(cur_trace_label).index.tolist()\n",
    "    random.shuffle(trace_indexs)\n",
    "    trace_data, trace_labels = np.array(cur_trace_data)[trace_indexs], np.array(cur_trace_label)[trace_indexs]\n",
    "    return trace_data, trace_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "098cdb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_data_label(cur_trace_data, cur_trace_label):\n",
    "    trace_indexs = pd.DataFrame(cur_trace_label).index.tolist()\n",
    "    random.shuffle(trace_indexs)\n",
    "    trace_data, trace_labels = np.array(cur_trace_data)[trace_indexs], np.array(cur_trace_label)[trace_indexs]\n",
    "    return trace_data, trace_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4a14ca22",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = np.concatenate([honda_trace_data,cadillac_trace_data])\n",
    "train_labels = np.concatenate([honda_trace_label,cadillac_trace_label])\n",
    "train_data, train_labels = shuffle_data_label(train_data, train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ab003f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = shuffle_data_label(chevy_trace_data, chevy_trace_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e03d2",
   "metadata": {},
   "source": [
    "## DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e2075a9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:526: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:527: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:528: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:529: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:530: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:535: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Input, Permute, BatchNormalization, Flatten, MaxPooling1D, Conv1D,Conv2D, MaxPooling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.losses import mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras.backend as K\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8039dced",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 之后需要加深Conv，增加maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "56fdf911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape = (1000,64,1))\n",
    "# x = keras.layers.Conv2D(15, 3, padding='same', data_format='channels_last')(inputs)\n",
    "# # x = layers.Lambda(lambda a: K.mean(a, axis=1, keepdims=True))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# outputs = Dense(64, activation='sigmoid')(x)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "# # keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# keras.optimizers.Adam(lr=1e-3)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "# # model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[my_acc])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f51c3c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape = (1000,64,1))\n",
    "# x = Conv2D(60, (3,3), padding='same', data_format='channels_last')(inputs)\n",
    "# x = Conv2D(30, (3,3), padding='same', data_format='channels_last')(x)\n",
    "# x = Conv2D(15, (3,3), padding='same', data_format='channels_last')(x)\n",
    "# x = layers.Lambda(lambda a: K.mean(a, axis=1, keepdims=True))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# outputs = Dense(64, activation='sigmoid')(x)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "# keras.optimizers.Adam(lr=1e-3)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "1a79708a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_msb = Sequential()\n",
    "# model_msb.add(Conv1D(256, 5, padding='same', input_shape = (1000,64)))\n",
    "# model_msb.add(MaxPooling1D(3, 3, padding='same'))\n",
    "# model_msb.add(Conv1D(128, 5, padding='same'))\n",
    "# model_msb.add(MaxPooling1D(3, 3, padding='same'))\n",
    "# model_msb.add(Conv1D(64, 3, padding='same'))\n",
    "# model_msb.add(Flatten())\n",
    "# model_msb.add(Dropout(0.1))\n",
    "# model_msb.add(BatchNormalization())  # (批)规范化层\n",
    "# model_msb.add(Dense(256, activation='relu'))\n",
    "# model_msb.add(Dropout(0.1))\n",
    "# model_msb.add(Dense(64, activation='sigmoid'))\n",
    "# # model_msb.compile(loss=my_loss,optimizer='adam',metrics=['accuracy'])\n",
    "# model_msb.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n",
    "# # one_hot_labels = keras.utils.to_categorical(y_train, num_classes=3)  # 将标签转换为one-hot编码\n",
    "# model_msb.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "ec70e697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape = (1000,64,1))\n",
    "# x = Conv2D(256, (3,3), padding='same', data_format='channels_last')(inputs)\n",
    "# x = MaxPooling2D(pool_size=3, strides=3, padding='valid')(x)\n",
    "# x = Conv2D(128, 3, padding='same', data_format='channels_last')(x)\n",
    "# # x = MaxPooling2D(pool_size=3, strides=3, padding='valid')(x)\n",
    "# x = Conv2D(64, 3, padding='same', data_format='channels_last')(x)\n",
    "# x = layers.Lambda(lambda a: K.mean(a, axis=1, keepdims=True))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# x = BatchNormalization()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# x = Dropout(0.1)(x)\n",
    "# outputs = Dense(64, activation='sigmoid')(x)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "# keras.optimizers.Adam(lr=1e-3)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "04f1ae69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_5 (InputLayer)            (None, 1000, 64, 1)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 1000, 64, 60) 600         input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 1000, 64, 30) 16230       conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 1000, 64, 15) 4065        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_14 (Dropout)            (None, 1000, 64, 15) 0           conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "add_5 (Add)                     (None, 1000, 64, 15) 0           dropout_14[0][0]                 \n",
      "                                                                 input_5[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_5 (Lambda)               (None, 1, 64, 15)    0           add_5[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_5 (Flatten)             (None, 960)          0           lambda_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dropout_15 (Dropout)            (None, 960)          0           flatten_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 960)          3840        dropout_15[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 64)           61504       batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 64)           0           dense_9[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_10 (Dense)                (None, 64)           4160        dropout_16[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 90,399\n",
      "Trainable params: 88,479\n",
      "Non-trainable params: 1,920\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape = (1000,64,1))\n",
    "x = Conv2D(60, (3,3), padding='same', data_format='channels_last')(inputs)\n",
    "x = Conv2D(30, (3,3), padding='same', data_format='channels_last')(x)\n",
    "x = Conv2D(15, (3,3), padding='same', data_format='channels_last')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = add([x,inputs])\n",
    "x = layers.Lambda(lambda a: K.mean(a, axis=1, keepdims=True))(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(64, activation='sigmoid')(x)\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "68853e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data_4 = np.expand_dims(cur_train_data, 3)\n",
    "# test_data_4 = np.expand_dims(cur_test_data, 3)\n",
    "train_data_4 = np.expand_dims(train_data, 3)\n",
    "test_data_4 = np.expand_dims(test_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "a7e33430",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain_data = train_data_4\n",
    "mytrain_labels = np.array(train_labels)\n",
    "# mytrain_labels = np.array(cur_train_labels)\n",
    "\n",
    "mytest_data = test_data_4\n",
    "mytest_labels = np.array(test_labels)\n",
    "# mytest_labels = np.array(cur_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "37457f34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.fit(mytrain_data, mytrain_labels,epochs=5, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "674a1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 285 samples, validate on 87 samples\n",
      "Epoch 1/1\n",
      "285/285 [==============================] - 44s 155ms/step - loss: 0.0123 - acc: 0.9972 - val_loss: 0.0858 - val_acc: 0.9779\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(mytrain_data, mytrain_labels,\n",
    "     epochs=1,\n",
    "     batch_size=32,\n",
    "     validation_data=(mytest_data, mytest_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6465b831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# acc = history.history['acc']\n",
    "# loss = history.history['loss']\n",
    "# epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "634f8cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.title('Accuracy')\n",
    "# plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "# plt.plot(epochs, loss, 'blue', label='Training loss')\n",
    "# plt.legend()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "d8271ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "18200 18240\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      1.00      1.00     16935\n",
      "         1.0       0.99      0.98      0.98      1305\n",
      "\n",
      "    accuracy                           1.00     18240\n",
      "   macro avg       0.99      0.99      0.99     18240\n",
      "weighted avg       1.00      1.00      1.00     18240\n",
      "\n",
      "混淆矩阵：\n",
      "[[16918    17]\n",
      " [   23  1282]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_prob = model.predict(mytrain_data)\n",
    "predict_target_msb_label = (predict_target_msb_prob > 0.5).astype(int)\n",
    "predict_target_msb_1D = predict_target_msb_label.flatten()\n",
    "train_labels_1D = mytrain_labels.flatten()\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_1D == train_labels_1D),len(train_labels_1D))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(train_labels_1D,predict_target_msb_1D))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(train_labels_1D,predict_target_msb_1D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "e39c7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "5445 5568\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      5417\n",
      "         1.0       0.58      0.66      0.62       151\n",
      "\n",
      "    accuracy                           0.98      5568\n",
      "   macro avg       0.79      0.82      0.80      5568\n",
      "weighted avg       0.98      0.98      0.98      5568\n",
      "\n",
      "混淆矩阵：\n",
      "[[5345   72]\n",
      " [  51  100]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_prob =model.predict(mytest_data)\n",
    "predict_target_test_msb_label = (predict_target_test_msb_prob > 0.5).astype(int)\n",
    "predict_target_test_msb_1D = predict_target_test_msb_label.flatten()\n",
    "test_labels_1D = mytest_labels.flatten()\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_1D == test_labels_1D),len(test_labels_1D))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(test_labels_1D,predict_target_test_msb_1D))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(test_labels_1D,predict_target_test_msb_1D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a466c",
   "metadata": {},
   "source": [
    "## READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7395272b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "97cc8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip\n",
    "import math\n",
    "inf = -11\n",
    "def get_preparation(trace_data):\n",
    "    bit_Flips = []\n",
    "    Magnitudes = []\n",
    "    for i in range(len(trace_data)):\n",
    "        messagelist = trace_data[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        magnitude = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "            if bit_flip[ix] == 0:\n",
    "                cur_magnitude = inf\n",
    "            else:\n",
    "                cur_magnitude = math.log10(bit_flip[ix])\n",
    "            magnitude[ix] = math.ceil(cur_magnitude)\n",
    "        bit_Flips.append(bit_flip)\n",
    "        Magnitudes.append(magnitude)\n",
    "    return bit_Flips, Magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "1408324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase1(magnitude):\n",
    "    ref = []\n",
    "    prevMagnitude = magnitude[0]\n",
    "    ixS = 0\n",
    "    for ix in range(64):\n",
    "        if magnitude[ix] < prevMagnitude:\n",
    "            ref.append((ixS, ix-1))\n",
    "            ixS = ix\n",
    "        prevMagnitude = magnitude[ix]\n",
    "    ref.append((ixS, 63))\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "adf3be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchCounter(sublist):\n",
    "    if(sublist[-1] != 1):\n",
    "        return -1\n",
    "    ixS = len(sublist)-1\n",
    "    for i in range(len(sublist)-2,-1,-1):\n",
    "        if sublist[i] == (sublist[i+1] / 2):\n",
    "            ixS = i\n",
    "    return ixS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "c45df11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase2(ref, bit_flip, magnitude):\n",
    "    rRef = []\n",
    "    for sign in ref:\n",
    "        (ixS, ixE) = sign\n",
    "        mgt = magnitude[ixS: ixE+1]\n",
    "        mu = np.mean(bit_flip[ixS: ixE+1])\n",
    "        std = np.std(bit_flip[ixS: ixE+1])\n",
    "        if magnitude[ixE] == 0:\n",
    "            Sctr = matchCounter(bit_flip[ixS: ixE+1])\n",
    "#             print(Sctr)\n",
    "            if Sctr >= 0:\n",
    "                rRef.append((ixS, Sctr, \"PHYSVAL\"))\n",
    "                rRef.append((Sctr, ixE, \"COUNTER\"))\n",
    "        else:\n",
    "            exit = False\n",
    "            for Scrc in range(ixS, ixE+1):\n",
    "                if not exit:\n",
    "#                     print(Scrc)\n",
    "                    if sum(magnitude[Scrc: (ixE+1)]) == 0 and mu >= (0.5-std) and mu <= (0.5+std):\n",
    "                        rRef.append((Scrc, ixE, \"CRC\"))\n",
    "                        rRef.append((ixS, Scrc, \"PHYSVAL\"))\n",
    "                        exit = True\n",
    "                else:\n",
    "                    break\n",
    "    return rRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "b65f9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position2preds(preds_ref):\n",
    "    preds = []\n",
    "    for i in range(len(preds_ref)):\n",
    "        cur_ref = preds_ref[i]\n",
    "        cur_preds = np.zeros(64)\n",
    "        for signal in cur_ref:\n",
    "            cur_preds[signal[1]] = 1\n",
    "        preds.append(cur_preds)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "f18ae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_score(y_true, y_pred):\n",
    "    new_labels = []\n",
    "    new_preds = []\n",
    "    for i in range(len(y_true)):\n",
    "        if(y_true[i] == 1):\n",
    "            new_labels.append(y_true[i])\n",
    "            new_preds.append(y_pred[i])\n",
    "    return np.array(new_labels), np.array(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e4520a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ_test_data = origin_trace\n",
    "# READ_test_labels = origin_label\n",
    "\n",
    "# READ_test_data = np.array(test_data_clear)\n",
    "# READ_test_labels = np.array(test_labels_clear)\n",
    "\n",
    "READ_test_data = np.array(test_data)\n",
    "READ_test_labels = np.array(test_labels)\n",
    "\n",
    "# READ_test_data = np.array(cur_test_data)\n",
    "# READ_test_labels = np.array(cur_test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "1a6e9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_flip_dict, magnitude_dict = get_preparation(READ_test_data)\n",
    "preds_ref = []\n",
    "preds_rRef = []\n",
    "for i in range(len(magnitude_dict)):\n",
    "    ref = get_phase1(magnitude_dict[i])\n",
    "    rRef = get_phase2(ref, bit_flip_dict[i], magnitude_dict[i])\n",
    "    preds_rRef.append(rRef)\n",
    "    preds_ref.append(ref)\n",
    "preds = position2preds(preds_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f49a7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ_test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "19f207a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "87"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bit_flip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5935dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(np.arange(64), bit_flip_dict[],label=\"bit-flip\")\n",
    "# # plt.bar(np.arange(64), READ_test_labels[10],label=\"label\",color=\"black\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "378ce051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(np.arange(64), bit_flip_dict[3],label=\"bit-flip\")\n",
    "# plt.bar(np.arange(64), preds[3],label=\"preds\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "ddf7f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(np.arange(64), magnitude_dict[1],label=\"magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "feb8cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "5353 5568\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.97      0.98      5417\n",
      "         1.0       0.37      0.62      0.47       151\n",
      "\n",
      "    accuracy                           0.96      5568\n",
      "   macro avg       0.68      0.80      0.72      5568\n",
      "weighted avg       0.97      0.96      0.97      5568\n",
      "\n",
      "混淆矩阵：\n",
      "[[5259  158]\n",
      " [  57   94]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"测试集:\")\n",
    "preds_msb_1D = preds.flatten()\n",
    "test_labels_1D = READ_test_labels.flatten()\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(preds_msb_1D == test_labels_1D),len(test_labels_1D))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(test_labels_1D,preds_msb_1D))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(test_labels_1D,preds_msb_1D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d081b1",
   "metadata": {},
   "source": [
    "## 4.CAN-D数据特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "17acac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip\n",
    "def get_bit_Flips(cur_id_traces):\n",
    "    bit_Flips = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_Flips.append(bit_flip)\n",
    "    return bit_Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7e6f91ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip\n",
    "def get_bit_Flips(cur_id_traces):\n",
    "    bit_Flips = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_Flips.append(bit_flip)\n",
    "    return bit_Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad9ae42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_constant_bit(cur_trace_data, cur_trace_label, bit_Flips):\n",
    "    for i in range(len(bit_Flips)):\n",
    "        cur_bit_flip = bit_Flips[i]\n",
    "        cur_constant_bits = []\n",
    "        for j in range(64):\n",
    "            if cur_bit_flip[j] == 0:\n",
    "                cur_constant_bits.append(j)\n",
    "        a = cur_trace_data[i]\n",
    "#         print(np.array(a).shape)\n",
    "        b = []\n",
    "        for temp in a:\n",
    "            b.append([temp[j] for j in range(len(temp)) if j not in cur_constant_bits])\n",
    "#         print(np.array(b).shape)\n",
    "        cur_trace_data[i] = b\n",
    "        temp = []\n",
    "        for j in range(len(cur_trace_label[i])):\n",
    "            next_j = j+1\n",
    "            if j not in cur_constant_bits:\n",
    "                if next_j in cur_constant_bits:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(cur_trace_label[i][j])\n",
    "        cur_trace_label[i] = temp\n",
    "#         cur_trace_label[i] = [temp[j] for j in range(len(temp)) if j not in cur_constant_bits]\n",
    "        temp = bit_Flips[i]\n",
    "        bit_Flips[i] = [temp[j] for j in range(len(temp)) if j not in cur_constant_bits]\n",
    "    return cur_trace_data, cur_trace_label, bit_Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "41c2fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip的联合概率\n",
    "def get_bit_Flip_LHs(cur_id_traces):\n",
    "    bit_Flip_LHs = []\n",
    "    bit_Flip_LH_nos = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        message_len = len(messagelist[0])\n",
    "        bit_flip_LH = np.zeros(message_len)\n",
    "        bit_flip_LH_no = np.zeros(message_len)\n",
    "        previous_LH = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(message_len-1):\n",
    "                if item[ix] != previous_LH[ix] and item[ix+1] != previous_LH[ix+1]:\n",
    "                    bit_flip_LH[ix] = bit_flip_LH[ix] + 1\n",
    "                if item[ix] == previous_LH[ix] and item[ix+1] == previous_LH[ix+1]:\n",
    "                    bit_flip_LH_no[ix] = bit_flip_LH_no[ix] + 1\n",
    "            previous_LH = item\n",
    "        for ix in range(message_len-1):\n",
    "            bit_flip_LH[ix] = bit_flip_LH[ix] / trace_len\n",
    "            bit_flip_LH_no[ix] = bit_flip_LH_no[ix] / trace_len\n",
    "\n",
    "        bit_flip_LH = np.append(bit_flip_LH, 0)\n",
    "        bit_flip_LH = np.append(bit_flip_LH, 0)\n",
    "        bit_flip_LH_no = np.append(bit_flip_LH_no, 0)\n",
    "        bit_flip_LH_no = np.append(bit_flip_LH_no, 0)\n",
    "\n",
    "        bit_Flip_LHs.append(bit_flip_LH)\n",
    "        bit_Flip_LH_nos.append(bit_flip_LH_no)\n",
    "    return bit_Flip_LHs, bit_Flip_LH_nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "cdb2cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_id_tracelist 通过大端bit序列得到小端bit序列\n",
    "def get_reverse_id_traces(cur_id_traces):\n",
    "    reverse_id_traces = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        id_tracelist = cur_id_traces[i]\n",
    "        reverse_id_tracelist = []\n",
    "        for item in id_tracelist:\n",
    "            cur_tracelist = [0,1,2,3,4,5,6,7]\n",
    "            cur_temp = []\n",
    "            count = 7\n",
    "            for i in range(64):\n",
    "                cur_temp.append(item[i])\n",
    "                if (i+1)%8 == 0:\n",
    "                    cur_tracelist[count] = cur_temp\n",
    "                    count = count - 1\n",
    "                    cur_temp = []\n",
    "            reverse_id_tracelist.append(np.concatenate(cur_tracelist).tolist())\n",
    "        reverse_id_traces[i] = reverse_id_tracelist\n",
    "    return reverse_id_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e6e8adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到每个bit的15个特征\n",
    "def get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i):\n",
    "    f1 = bit_Flips[i][ix]\n",
    "#     print(bit_Flips[i], i, ix)\n",
    "    f2 = bit_Flips_LH[i][ix] / bit_Flips[i][ix+1]\n",
    "    f3 = bit_Flips_LH[i][ix] / bit_Flips[i][ix]\n",
    "    f4 = bit_Flip_LH_nos[i][ix] / (1 - bit_Flips[i][ix+1])\n",
    "    f5 = bit_Flip_LH_nos[i][ix] / (1 - bit_Flips[i][ix])\n",
    "    return np.array([f1,f2,f3,f4,f5])\n",
    "\n",
    "def get_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i):\n",
    "    cur_bit_feature = []\n",
    "    feature_sub1 = get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i)\n",
    "    feature_sub2 = get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix+1, i)\n",
    "    feature_sub3 = feature_sub2 - feature_sub1\n",
    "    return np.concatenate((feature_sub1,feature_sub2,feature_sub3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6606d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个bit赋予15个特征\n",
    "def get_bit_features_list(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos):\n",
    "    bit_features_list = []\n",
    "    for i in range(len(bit_Flips)):\n",
    "        bit_features = []\n",
    "        for ix in range(len(bit_Flips[i])-2):\n",
    "            bit_features.append(get_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i))\n",
    "        bit_features_list.append(bit_features)\n",
    "    return bit_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "a6a3d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小端转成大端的正常格式，方便与上边生成的ground truth label匹配\n",
    "def LE_to_BE(reverse_bit_features_list):\n",
    "    bit_features_list = []\n",
    "    for i in range(len(reverse_bit_features_list)):\n",
    "        item = reverse_bit_features_dict[i]\n",
    "        cur_bit_features = [0,1,2,3,4,5,6,7]\n",
    "        cur_temp = []\n",
    "        count = 7\n",
    "        for i in range(64):\n",
    "            cur_temp.append(item[i])\n",
    "            if (i+1)%8 == 0:\n",
    "                cur_bit_features[count] = cur_temp\n",
    "                count = count - 1\n",
    "                cur_temp = []\n",
    "        bit_features_list.append(np.concatenate(cur_bit_features).tolist())\n",
    "    return bit_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "110be394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Trace与Ground Truth都存在的id\n",
    "def get_all_datas_labels(bit_features_list, cur_id_labels):\n",
    "    alldatas = []\n",
    "    alllabels = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for i in range(len(cur_features)):\n",
    "            alldatas.append(cur_features[i])\n",
    "            alllabels.append(int(cur_labels[i]))\n",
    "    return alldatas, alllabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "05836d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffle_data_label(cur_trace_data, cur_trace_label):\n",
    "    trace_indexs = pd.DataFrame(cur_trace_label).index.tolist()\n",
    "    random.shuffle(trace_indexs)\n",
    "    trace_data, trace_labels = np.array(cur_trace_data)[trace_indexs], np.array(cur_trace_label)[trace_indexs]\n",
    "    return trace_data, trace_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f583f",
   "metadata": {},
   "source": [
    "## 5.训练大端的RF模型，去掉constant bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c47e5",
   "metadata": {},
   "source": [
    "### 预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "07787c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_id_traces, train_id_labels = get_trace_data(train_data_dict, train_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f4f0c635",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(train_id_labels).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "15494e54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.array(cur_train_data).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "66e9c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# train_id_traces, train_id_labels = get_trace_data(train_data_dict, train_label_dict)\n",
    "train_id_traces = train_data.tolist()\n",
    "train_id_labels = train_labels.tolist()\n",
    "bit_Flips_train = get_bit_Flips(train_id_traces)\n",
    "train_id_traces, train_id_labels, bit_Flips_train = del_constant_bit(train_id_traces, train_id_labels, bit_Flips_train)\n",
    "bit_Flip_LHs_train, bit_Flip_LH_nos_train = get_bit_Flip_LHs(train_id_traces)\n",
    "bit_features_list_train = get_bit_features_list(bit_Flips_train, bit_Flip_LHs_train, bit_Flip_LH_nos_train)\n",
    "traindatas_msb, trainlabels_msb = get_all_datas_labels(bit_features_list_train, train_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "40f6d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# test_id_traces, test_id_labels = get_trace_data(test_data_dict, test_label_dict)\n",
    "test_id_traces = test_data.tolist()\n",
    "test_id_labels = test_labels.tolist()\n",
    "bit_Flips_test = get_bit_Flips(test_id_traces)\n",
    "test_id_traces, test_id_labels, bit_Flips_test = del_constant_bit(test_id_traces, test_id_labels, bit_Flips_test)\n",
    "bit_Flip_LHs_test, bit_Flip_LH_nos_test = get_bit_Flip_LHs(test_id_traces)\n",
    "bit_features_list_test = get_bit_features_list(bit_Flips_test, bit_Flip_LHs_test, bit_Flip_LH_nos_test)\n",
    "testdatas_msb, testlabels_msb = get_all_datas_labels(bit_features_list_test, test_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "08b3f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_msb, trainlabels_msb = get_shuffle_data_label(traindatas_msb, trainlabels_msb)\n",
    "testdatas_msb, testlabels_msb = get_shuffle_data_label(testdatas_msb, testlabels_msb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f255541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traindata_msb = pd.DataFrame(traindatas_msb)\n",
    "Traindata_msb['label'] = np.array(trainlabels_msb)\n",
    "Traindata_msb = Traindata_msb.fillna(0)\n",
    "traindatas_msb = np.array(Traindata_msb.iloc[:,:15])\n",
    "trainlabels_msb = np.array(Traindata_msb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "82ee54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata_msb = pd.DataFrame(testdatas_msb)\n",
    "Testdata_msb['label'] = np.array(testlabels_msb)\n",
    "Testdata_msb = Testdata_msb.fillna(0)\n",
    "testdatas_msb = np.array(Testdata_msb.iloc[:,:15])\n",
    "testlabels_msb = np.array(Testdata_msb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f06bd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "10207 10223\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      8973\n",
      "           1       1.00      0.99      0.99      1250\n",
      "\n",
      "    accuracy                           1.00     10223\n",
      "   macro avg       1.00      1.00      1.00     10223\n",
      "weighted avg       1.00      1.00      1.00     10223\n",
      "\n",
      "混淆矩阵：\n",
      "[[8967    6]\n",
      " [  10 1240]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "817 840\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98       680\n",
      "           1       0.99      0.87      0.92       160\n",
      "\n",
      "    accuracy                           0.97       840\n",
      "   macro avg       0.98      0.93      0.95       840\n",
      "weighted avg       0.97      0.97      0.97       840\n",
      "\n",
      "混淆矩阵：\n",
      "[[678   2]\n",
      " [ 21 139]]\n"
     ]
    }
   ],
   "source": [
    "#随机森林方法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "model_msb = RandomForestClassifier(n_estimators= 30)\n",
    "model_msb.fit(traindatas_msb, trainlabels_msb)\n",
    "\n",
    "print(\"训练集:\")\n",
    "predict_target_msb = model_msb.predict(traindatas_msb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb == trainlabels_msb),len(trainlabels_msb))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_msb,predict_target_msb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb,predict_target_msb))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_msb =model_msb.predict(testdatas_msb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb == testlabels_msb),len(testlabels_msb))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_msb,predict_target_test_msb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb,predict_target_test_msb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e91464",
   "metadata": {},
   "source": [
    "### 微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "68bc5dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# train_id_traces_f, train_id_labels_f = get_trace_data(train_data_dict, train_label_dict)\n",
    "# train_id_traces_f, train_id_labels_f = cur_train_data.tolist(), train_labels.tolist()\n",
    "train_id_traces_f = train_data.tolist()\n",
    "train_id_labels_f = train_labels.tolist()\n",
    "bit_Flips_train_f = get_bit_Flips(train_id_traces_f)\n",
    "bit_Flip_LHs_train_f, bit_Flip_LH_nos_train_f = get_bit_Flip_LHs(train_id_traces_f)\n",
    "bit_features_list_train_f = get_bit_features_list(bit_Flips_train_f, bit_Flip_LHs_train_f, bit_Flip_LH_nos_train_f)\n",
    "traindatas_msb_f, trainlabels_msb_f = get_all_datas_labels(bit_features_list_train_f, train_id_labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2f9108e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "# test_id_traces_f, test_id_labels_f = get_trace_data(test_data_dict, test_label_dict)\n",
    "# test_id_traces_f, test_id_labels_f = test_data.tolist(), test_labels.tolist()\n",
    "test_id_traces_f = test_data.tolist()\n",
    "test_id_labels_f = test_labels.tolist()\n",
    "bit_Flips_test_f = get_bit_Flips(test_id_traces_f)\n",
    "bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f = get_bit_Flip_LHs(test_id_traces_f)\n",
    "bit_features_list_test_f = get_bit_features_list(bit_Flips_test_f, bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f)\n",
    "testdatas_msb_f, testlabels_msb_f = get_all_datas_labels(bit_features_list_test_f, test_id_labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f442a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_msb_f, trainlabels_msb_f = get_shuffle_data_label(traindatas_msb_f, trainlabels_msb_f)\n",
    "testdatas_msb_f, testlabels_msb_f = get_shuffle_data_label(testdatas_msb_f, testlabels_msb_f)\n",
    "\n",
    "Traindata_msb_f = pd.DataFrame(traindatas_msb_f)\n",
    "Traindata_msb_f['label'] = np.array(trainlabels_msb_f)\n",
    "Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "traindatas_msb_f = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "trainlabels_msb_f = np.array(Traindata_msb_f.iloc[:,-1])\n",
    "\n",
    "Testdata_msb_f = pd.DataFrame(testdatas_msb_f)\n",
    "Testdata_msb_f['label'] = np.array(testlabels_msb_f)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "testdatas_msb_f = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "testlabels_msb_f = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c2d4dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nonobvious_boundary(cur_features, j):\n",
    "    if j == 0:\n",
    "        if cur_features[1][0] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    if j == 63:\n",
    "        if cur_features[62][0] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    if cur_features[j-1][0] != 0 and cur_features[j+1][0] != 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "8815ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tun_data_label(bit_features_list, cur_id_labels):\n",
    "    nonobvious_boundaries = []\n",
    "    nonobvious_boundaries_label = []\n",
    "    obvious_boundaries = []\n",
    "    obvious_boundaries_label = []\n",
    "    negative_bit = []\n",
    "    negativ_bit_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 0:\n",
    "                negative_bit.append(cur_features[j])\n",
    "                negativ_bit_label.append(int(cur_labels[j]))\n",
    "            elif is_nonobvious_boundary(cur_features, j):\n",
    "                nonobvious_boundaries.append(cur_features[j])\n",
    "                nonobvious_boundaries_label.append(int(cur_labels[j]))\n",
    "            else:\n",
    "                obvious_boundaries.append(cur_features[j])\n",
    "                obvious_boundaries_label.append(int(cur_labels[j]))\n",
    "#     print(np.array(obvious_boundaries).shape)\n",
    "    len_nb = len(nonobvious_boundaries_label)\n",
    "    len_ne = int(len_nb/8 * 4)\n",
    "    len_ob = int(len_nb/8)\n",
    "    train_data = np.concatenate([nonobvious_boundaries, negative_bit[:len_ne], obvious_boundaries[:len_ob]])\n",
    "    train_label = np.concatenate([nonobvious_boundaries_label, negativ_bit_label[:len_ne], obvious_boundaries_label[:len_ob]])\n",
    "    tun_data, tun_label = get_shuffle_data_label(train_data, train_label)\n",
    "    return tun_data, tun_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "a3d21b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_label(bit_features_list, cur_id_labels):\n",
    "    nonobvious_boundaries = []\n",
    "    nonobvious_boundaries_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 1 and is_nonobvious_boundary(cur_features, j):\n",
    "                nonobvious_boundaries.append(cur_features[j])\n",
    "                nonobvious_boundaries_label.append(int(cur_labels[j]))\n",
    "    test_data, test_label = get_shuffle_data_label(nonobvious_boundaries, nonobvious_boundaries_label)\n",
    "    return test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5383e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label_boundary(bit_features_list, cur_id_labels):\n",
    "    boundaries = []\n",
    "    boundaries_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 1:\n",
    "                boundaries.append(cur_features[j])\n",
    "                boundaries_label.append(int(cur_labels[j]))\n",
    "    test_data, test_label = get_shuffle_data_label(boundaries, boundaries_label)\n",
    "    return test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "57ad4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label_boundary_constant(bit_features_list, cur_id_labels):\n",
    "    nonobvious_boundaries = []\n",
    "    nonobvious_boundaries_label = []\n",
    "    negative_bit = []\n",
    "    negativ_bit_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 0:\n",
    "                negative_bit.append(cur_features[j])\n",
    "                negativ_bit_label.append(int(cur_labels[j]))\n",
    "            elif is_nonobvious_boundary(cur_features, j):\n",
    "                nonobvious_boundaries.append(cur_features[j])\n",
    "                nonobvious_boundaries_label.append(int(cur_labels[j]))\n",
    "    train_data = np.concatenate([nonobvious_boundaries, negative_bit])\n",
    "    train_label = np.concatenate([nonobvious_boundaries_label, negativ_bit_label])\n",
    "    tun_data, tun_label = get_shuffle_data_label(train_data, train_label)\n",
    "    return tun_data, tun_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be55daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_data, tun_label = get_tun_data_label(bit_features_list_train_f, train_id_labels_f)\n",
    "\n",
    "Traindata_msb_f = pd.DataFrame(tun_data)\n",
    "Traindata_msb_f['label'] = np.array(tun_label)\n",
    "Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "tun_data = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "tun_label = np.array(Traindata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "a679b145",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87, 64)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(test_id_labels_f).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "408a1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tun_data_2, tun_label_2 = get_tun_data_label(bit_features_list_test_f, test_id_labels_f)\n",
    "\n",
    "# Traindata_msb_f = pd.DataFrame(tun_data_2)\n",
    "# Traindata_msb_f['label'] = np.array(tun_label_2)\n",
    "# Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "# tun_data_2 = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "# tun_label_2 = np.array(Traindata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cac30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tun_test_data, tun_test_label = get_test_data_label(bit_features_list_test_f, test_id_labels_f)\n",
    "\n",
    "# Testdata_msb_f = pd.DataFrame(tun_test_data)\n",
    "# Testdata_msb_f['label'] = np.array(tun_test_label)\n",
    "# Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "# tun_test_data = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "# tun_test_label = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6894112",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit_features_list_f = np.concatenate([bit_features_list_train_f,bit_features_list_test_f])\n",
    "# id_labels_f = np.concatenate([train_id_labels_f,test_id_labels_f])\n",
    "\n",
    "# tun_test_data_all, tun_test_label_all = get_test_data_label(bit_features_list_f, id_labels_f)\n",
    "\n",
    "# Testdata_msb_f = pd.DataFrame(tun_test_data_all)\n",
    "# Testdata_msb_f['label'] = np.array(tun_test_label_all)\n",
    "# Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "# tun_test_data_all = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "# tun_test_label_all = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c481cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# bit_features_list_f = np.concatenate([bit_features_list_train_f,bit_features_list_test_f])\n",
    "# id_labels_f = np.concatenate([train_id_labels_f,test_id_labels_f])\n",
    "\n",
    "# tun_test_data_boundary, tun_test_label_boundary = get_data_label_boundary(bit_features_list_f, id_labels_f)\n",
    "\n",
    "# Testdata_msb_f = pd.DataFrame(tun_test_data_boundary)\n",
    "# Testdata_msb_f['label'] = np.array(tun_test_label_boundary)\n",
    "# Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "# tun_test_data_boundary = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "# tun_test_label_boundary = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7607190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f1_data, f1_label = get_data_label_boundary_constant(bit_features_list_train_f, train_id_labels_f)\n",
    "\n",
    "# Traindata_msb_f = pd.DataFrame(f1_data)\n",
    "# Traindata_msb_f['label'] = np.array(f1_label)\n",
    "# Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "# f1_data = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "# f1_label = np.array(Traindata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c9327fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 300, 'min_samples_leaf': 3, 'max_features': 6, 'max_depth': 5}\n",
      "-0.04533799533799534\n",
      "RandomForestClassifier(max_depth=5, max_features=6, min_samples_leaf=3,\n",
      "                       n_estimators=300)\n"
     ]
    }
   ],
   "source": [
    "param_distribution = [\n",
    "    {'n_estimators' : [90,150,200,250,300], 'max_features' : [1, 2, 3, 4, 5, 6], \n",
    "     'max_depth':[1,2,3,4,5],'min_samples_leaf':[3,4,5,6]},\n",
    "#     {'bootstrap' : [False], 'n_estimators' : [3, 10], 'max_features' : [2, 3, 4]},\n",
    "]\n",
    " \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scikitlearn.scikit_learn.sklearn.model_selection._search import RandomizedSearchCV\n",
    " \n",
    "random_search_cv = RandomizedSearchCV(model_msb,\n",
    "                                      param_distribution,\n",
    "                                      n_iter = 50,#从param_distribution里sample出多少个参数集合\n",
    "                                      cv = 10,\n",
    "                                      scoring='neg_mean_squared_error',\n",
    "#                                       scoring=my_scores,\n",
    "                                      n_jobs = 1) #有多少任务并行处理\n",
    "# random_search_cv.fit(traindatas_msb_f, trainlabels_msb_f)\n",
    "random_search_cv.fit(tun_data, tun_label)\n",
    " \n",
    "# 在超参数搜索时有cross_validation机制: 训练集分成n份，n-1训练，最后一份验证.\n",
    "# 在超参数搜索完之后，会在全部训练集上用新的参数再训练一遍\n",
    " \n",
    "print(random_search_cv.best_params_) #最好参数\n",
    "print(random_search_cv.best_score_) #最好分值\n",
    "print(random_search_cv.best_estimator_) #最好的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e6c83e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tunning = random_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2bd81145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "750 774\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.95      0.95       238\n",
      "           1       0.98      0.98      0.98       536\n",
      "\n",
      "    accuracy                           0.97       774\n",
      "   macro avg       0.96      0.96      0.96       774\n",
      "weighted avg       0.97      0.97      0.97       774\n",
      "\n",
      "混淆矩阵：\n",
      "[[225  13]\n",
      " [ 11 525]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(tun_data)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == tun_label),len(tun_label))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_label,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_label,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71631424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(tun_data_2)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == tun_label_2),len(tun_label_2))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_label_2,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_label_2,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d0936f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(tun_test_data)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == tun_test_label),len(tun_test_label))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_test_label,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_test_label,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4d03fe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(tun_test_data_all)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == tun_test_label_all),len(tun_test_label_all))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_test_label_all,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_test_label_all,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "966cf648",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(tun_test_data_boundary)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == tun_test_label_boundary),len(tun_test_label_boundary))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_test_label_boundary,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_test_label_boundary,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94621c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(traindatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == trainlabels_msb_f),len(trainlabels_msb_f))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_msb_f,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb_f,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b0ddc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(f1_data)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == f1_label),len(f1_label))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(f1_label,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(f1_label,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "c6d70cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "5425 5568\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.98      0.99      5417\n",
      "           1       0.52      0.62      0.57       151\n",
      "\n",
      "    accuracy                           0.97      5568\n",
      "   macro avg       0.76      0.80      0.78      5568\n",
      "weighted avg       0.98      0.97      0.98      5568\n",
      "\n",
      "混淆矩阵：\n",
      "[[5332   85]\n",
      " [  58   93]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(testdatas_msb_f)\n",
    "# predict_target_test_msb_f =model_msb.predict(testdatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == testlabels_msb_f),len(testlabels_msb_f))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_msb_f,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f939a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_data_dict = {}\n",
    "cur_label_dict = {}\n",
    "# '1a1', '32a', '348', 'be'\n",
    "id = \"1a1\"\n",
    "# cur_data_dict[id] = test_data_dict[id]\n",
    "# cur_label_dict[id] = test_label_dict[id]\n",
    "# cur_data,cur_label = get_trace_data(cur_data_dict, cur_label_dict)\n",
    "test_message_1 = {}\n",
    "test_message_label_1 = {}\n",
    "test_message_1[id] = new_checy_data_dict[id]\n",
    "test_message_label_1[id] = new_chevy_label_dict[id]\n",
    "cur_data,cur_label = get_trace_data(test_message_1, test_message_label_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "530337f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \"\"\"\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  \n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\ipykernel_launcher.py:15: RuntimeWarning: invalid value encountered in subtract\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "bit_Flips_test_f = get_bit_Flips(cur_data)\n",
    "bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f = get_bit_Flip_LHs(test_id_traces_f)\n",
    "bit_features_list_test_f = get_bit_features_list(bit_Flips_test_f, bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f)\n",
    "curdatas_msb_f, curlabels_msb_f = get_all_datas_labels(bit_features_list_test_f, cur_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "fb2883b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata_msb_f = pd.DataFrame(curdatas_msb_f)\n",
    "Testdata_msb_f['label'] = np.array(curlabels_msb_f)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "curdatas_msb_f = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "curlabels_msb_f = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2843882a",
   "metadata": {},
   "outputs": [],
   "source": [
    "curdatas_msb_f = np.nan_to_num(curdatas_msb_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "1708aa15",
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata = np.array(curdatas_msb_f[:64].tolist())\n",
    "testlabel = np.array(curlabels_msb_f[:64].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2e7d16ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>64 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0    1    2    3    4    5    6    7    8    9    10   11   12   13   14\n",
       "0   0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "1   0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "2   0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "3   0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "4   0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...\n",
       "59  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "60  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "61  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0\n",
       "62  0.0  0.0  0.0  1.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0 -1.0 -1.0\n",
       "63  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0\n",
       "\n",
       "[64 rows x 15 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(testdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "d70dad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\numpy\\core\\fromnumeric.py:87: RuntimeWarning: invalid value encountered in reduce\n",
      "  return ufunc.reduce(obj, axis, dtype, out, **passkwargs)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float32').",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_10192\\1788197031.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"测试集:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpredict_target_test_msb_f\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0mmodel_tunning\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"预测正确数量,训练集样本量:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpredict_target_test_msb_f\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mtestlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtestlabel\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"测试集精确度等指标：\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    806\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    807\u001b[0m         \"\"\"\n\u001b[1;32m--> 808\u001b[1;33m         \u001b[0mproba\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    809\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    810\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    848\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m         \u001b[1;31m# Check data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 850\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_X_predict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    851\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    852\u001b[0m         \u001b[1;31m# Assign chunk of trees to jobs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\sklearn\\ensemble\\_forest.py\u001b[0m in \u001b[0;36m_validate_X_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    577\u001b[0m         Validate X whenever one tries to predict, apply, predict_proba.\"\"\"\n\u001b[0;32m    578\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 579\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    580\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindices\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindptr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    581\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"No support for np.int64 index based sparse matrices\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    564\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 566\u001b[1;33m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 800\u001b[1;33m             \u001b[0m_assert_all_finite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mallow_nan\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mforce_all_finite\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"allow-nan\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    801\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    802\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_samples\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\keras_py3.7\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[1;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[0;32m    114\u001b[0m             raise ValueError(\n\u001b[0;32m    115\u001b[0m                 msg_err.format(\n\u001b[1;32m--> 116\u001b[1;33m                     \u001b[0mtype_err\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    117\u001b[0m                 )\n\u001b[0;32m    118\u001b[0m             )\n",
      "\u001b[1;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float32')."
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(testdata)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == testlabel),len(testlabel))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabel,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabel,predict_target_test_msb_f))\n",
    "plt.plot(predict_target_test_msb_f)\n",
    "plt.bar(np.arange(64),testlabel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87a7de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_list(arr, length):\n",
    "    res = []\n",
    "    last_i = 0\n",
    "    for i in range(length,len(arr),length):\n",
    "        res.append(arr[last_i:i])\n",
    "        last_i = i\n",
    "    res.append(arr[last_i:len(arr)])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83ff155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def cal_score_mean(labels, preds):\n",
    "    new_labels = clip_list(labels,64)\n",
    "    new_preds = clip_list(preds,64)\n",
    "    f1_score = 0\n",
    "    precision_score = 0\n",
    "    recall_score = 0\n",
    "    for i in range(len(new_labels)):\n",
    "        cur_label = new_labels[i]\n",
    "        cur_pred = new_preds[i]\n",
    "        f1_score = f1_score + sklearn.metrics.f1_score(cur_label, cur_pred)\n",
    "        precision_score = precision_score + sklearn.metrics.precision_score(cur_label, cur_pred)\n",
    "        recall_score = recall_score + sklearn.metrics.recall_score(cur_label, cur_pred)\n",
    "    res_f1_score = f1_score / len(new_labels)\n",
    "    res_precision_score = precision_score / len(new_labels)\n",
    "    res_recall_score = recall_score / len(new_labels)\n",
    "    return res_precision_score, res_recall_score, res_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ac1bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "79240 120000\n",
      "训练集精确度等指标：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10733179380598669 0.5150875805675805 0.17253723704633905\n",
      "混淆矩阵：\n",
      "[[74831 36619]\n",
      " [ 4141  4409]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "11401 16128\n",
      "测试集精确度等指标：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12101254383273913 0.5534653507867794 0.19326915181059473\n",
      "混淆矩阵：\n",
      "[[10806  4272]\n",
      " [  455   595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(traindatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == trainlabels_msb_f),len(trainlabels_msb_f))\n",
    "print(\"训练集精确度等指标：\")\n",
    "res_precision_score, res_recall_score, res_f1_score = cal_score_mean(trainlabels_msb_f,predict_target_msb_f)\n",
    "print(res_precision_score, res_recall_score, res_f1_score)\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb_f,predict_target_msb_f))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(testdatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == testlabels_msb_f),len(testlabels_msb_f))\n",
    "print(\"测试集精确度等指标：\")\n",
    "res_precision_score_test, res_recall_score_test, res_f1_score_test = cal_score_mean(testlabels_msb_f,predict_target_test_msb_f)\n",
    "print(res_precision_score_test, res_recall_score_test, res_f1_score_test)\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"训练集:\")\n",
    "# predict_target_msb_f = model_msb.predict(traindatas_msb_f)\n",
    "# print(\"预测正确数量,训练集样本量:\")\n",
    "# print(sum(predict_target_msb_f == trainlabels_msb_f),len(trainlabels_msb_f))\n",
    "# print(\"训练集精确度等指标：\")\n",
    "# print(metrics.classification_report(trainlabels_msb_f,predict_target_msb_f))\n",
    "# print(\"混淆矩阵：\")\n",
    "# print(metrics.confusion_matrix(trainlabels_msb_f,predict_target_msb_f))\n",
    "\n",
    "# print(\"测试集:\")\n",
    "# predict_target_test_msb_f =model.predict(testdatas_msb_f)\n",
    "# print(\"预测正确数量,训练集样本量:\")\n",
    "# print(sum(predict_target_test_msb_f == testlabels_msb_f),len(testlabels_msb_f))\n",
    "# print(\"测试集精确度等指标：\")\n",
    "# print(metrics.classification_report(testlabels_msb_f,predict_target_test_msb_f))\n",
    "# print(\"混淆矩阵：\")\n",
    "# print(metrics.confusion_matrix(testlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4adcf",
   "metadata": {},
   "source": [
    "## 训练小端的RF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11dfd71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "reverse_train_data_dict = get_reverse_id_tracedict(train_data_dict)\n",
    "reverse_bit_flip_dict_train = get_bit_flip_dict(reverse_train_data_dict)\n",
    "reverse_bit_flip_LH_dict_train, reverse_bit_flip_LH_no_dict_train = get_bit_flip_LH_dict(reverse_train_data_dict)\n",
    "reverse_bit_features_dict_train = get_bit_features_dict(reverse_bit_flip_dict_train, reverse_bit_flip_LH_dict_train, reverse_bit_flip_LH_no_dict_train)\n",
    "bit_features_dict_train_lsb = LE_to_BE(reverse_bit_features_dict_train)\n",
    "traindatas_lsb, trainlabels_lsb = get_all_datas_labels(bit_features_dict_train_lsb, train_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cf86408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "reverse_test_data_dict = get_reverse_id_tracedict(test_data_dict)\n",
    "reverse_bit_flip_dict_test = get_bit_flip_dict(reverse_test_data_dict)\n",
    "reverse_bit_flip_LH_dict_test, reverse_bit_flip_LH_no_dict_test = get_bit_flip_LH_dict(reverse_test_data_dict)\n",
    "reverse_bit_features_dict_test = get_bit_features_dict(reverse_bit_flip_dict_test, reverse_bit_flip_LH_dict_test, reverse_bit_flip_LH_no_dict_test)\n",
    "bit_features_dict_test_lsb = LE_to_BE(reverse_bit_features_dict_test)\n",
    "testdatas_lsb, testlabels_lsb = get_all_datas_labels(bit_features_dict_test_lsb, test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0150d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_lsb, trainlabels_lsb = get_shuffle_data_label(traindatas_lsb, trainlabels_lsb)\n",
    "testdatas_lsb, testlabels_lsb = get_shuffle_data_label(testdatas_lsb, testlabels_lsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c11316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traindata_lsb = pd.DataFrame(traindatas_lsb)\n",
    "Traindata_lsb['label'] = np.array(trainlabels_lsb)\n",
    "Traindata_lsb = Traindata_lsb.fillna(0)\n",
    "traindatas_lsb = np.array(Traindata_lsb.iloc[:,:15])\n",
    "trainlabels_lsb = np.array(Traindata_lsb.iloc[:,-1])\n",
    "\n",
    "Testdata_lsb = pd.DataFrame(testdatas_lsb)\n",
    "Testdata_lsb['label'] = np.array(testlabels_lsb)\n",
    "Testdata_lsb = Testdata_lsb.fillna(0)\n",
    "testdatas_lsb = np.array(Testdata_lsb.iloc[:,:15])\n",
    "testlabels_lsb = np.array(Testdata_lsb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c13e221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "2717 2944\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2644\n",
      "           1       0.95      0.26      0.40       300\n",
      "\n",
      "    accuracy                           0.92      2944\n",
      "   macro avg       0.94      0.63      0.68      2944\n",
      "weighted avg       0.93      0.92      0.90      2944\n",
      "\n",
      "混淆矩阵：\n",
      "[[2640    4]\n",
      " [ 223   77]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "1138 1280\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1142\n",
      "           1       0.43      0.09      0.14       138\n",
      "\n",
      "    accuracy                           0.89      1280\n",
      "   macro avg       0.66      0.54      0.54      1280\n",
      "weighted avg       0.85      0.89      0.85      1280\n",
      "\n",
      "混淆矩阵：\n",
      "[[1126   16]\n",
      " [ 126   12]]\n"
     ]
    }
   ],
   "source": [
    "#随机森林方法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "model_lsb = RandomForestClassifier(n_estimators= 30)\n",
    "model_lsb.fit(traindatas_lsb, trainlabels_lsb)\n",
    "\n",
    "print(\"训练集:\")\n",
    "predict_target_lsb = model_lsb.predict(traindatas_lsb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_lsb == trainlabels_lsb), len(trainlabels_lsb))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_lsb, predict_target_lsb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_lsb, predict_target_lsb))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_lsb = model_lsb.predict(testdatas_lsb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_lsb == testlabels_lsb),len(testlabels_lsb))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_lsb, predict_target_test_lsb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_lsb, predict_target_test_lsb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c31dee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model/CAN-D_FR_LSB.model']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF大端模型保存\n",
    "joblib.dump(filename='./Model/CAN-D_FR_LSB.model', value=model_lsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10724fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = []\n",
    "setlist1 = ['JB', 'C']\n",
    "setlist2 = ['JB', 'JL', 'C']\n",
    "setlist3 = ['JL', 'C']\n",
    "flag = True\n",
    "count = 0\n",
    "for a in setlist1:\n",
    "    for b in setlist2:\n",
    "        for c in setlist2:\n",
    "            for d in setlist2:\n",
    "                for e in setlist2:\n",
    "                    for f in setlist2:\n",
    "                        for g in setlist2:\n",
    "                            for h in setlist3:\n",
    "                                v = [a,b,c,d,e,f,g,h]\n",
    "                                for i in range(8):\n",
    "                                    if(v[i] == 'JB' and v[i+1] == 'JL'):\n",
    "                                        flag = False\n",
    "                                        break\n",
    "                                    if(v[i] == 'JB' and i<6 and v[i+2] == 'JL'):\n",
    "                                        flag = False\n",
    "                                        break\n",
    "                                if flag == True:\n",
    "                                    V.append(v)\n",
    "                                    count = count + 1\n",
    "                                flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d02dda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for v in V:\n",
    "    e = ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "    for i in range(8):\n",
    "        if v[i] == 'JB':\n",
    "            e[i] = 'B'\n",
    "            e[i+1] = 'B'\n",
    "        if v[i] == 'JL':\n",
    "            e[i] = 'L'\n",
    "            e[i-1] = 'L'\n",
    "    E.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d2e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "EB = pd.DataFrame(E).replace('C', 'B')\n",
    "EB = np.array(EB).tolist()\n",
    "\n",
    "EL = pd.DataFrame(E).replace('C', 'L')\n",
    "EL = np.array(EL).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a307fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到所有可能的信号标记集合T\n",
    "def get_T(proba_msb, proba_lsb):\n",
    "    T = []\n",
    "    for e in EB:\n",
    "        t = []\n",
    "        for i in range(8):\n",
    "            if e[i] == 'B':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_msb[j])\n",
    "            if e[i] == 'L':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_lsb[j])\n",
    "        T.append(t)\n",
    "    for e in EL:\n",
    "        t = []\n",
    "        for i in range(8):\n",
    "            if e[i] == 'B':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_msb[j])\n",
    "            if e[i] == 'L':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_lsb[j])\n",
    "        T.append(t)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4d51985",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_msb_dict = {}\n",
    "for id in bit_features_dict_test.keys():\n",
    "    cur_predictproba_msb = []\n",
    "    temp = pd.DataFrame(bit_features_dict_test[id]).fillna(0)\n",
    "    cur_predict_proba_msb = model_msb.predict_proba(temp)\n",
    "    for prediction in cur_predict_proba_msb:\n",
    "        cur_predictproba_msb.append(prediction[1])\n",
    "    predict_proba_msb_dict[id] = cur_predictproba_msb\n",
    "    \n",
    "predict_proba_lsb_dict = {}\n",
    "for id in bit_features_dict_test_lsb.keys():\n",
    "    cur_predictproba_lsb = []\n",
    "    temp = pd.DataFrame(bit_features_dict_test_lsb[id]).fillna(0)\n",
    "    cur_predict_proba_lsb = model_lsb.predict_proba(temp)\n",
    "    for prediction in cur_predict_proba_lsb:\n",
    "        cur_predictproba_lsb.append(prediction[1])\n",
    "    predict_proba_lsb_dict[id] = cur_predictproba_lsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8584235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 0.6\n",
    "final_label_dict = {}\n",
    "for id in predict_proba_msb_dict.keys():\n",
    "    curT = get_T(predict_proba_msb_dict[id], predict_proba_lsb_dict[id])\n",
    "    mint0 = []\n",
    "    for t in curT:\n",
    "        t0 = 0\n",
    "        for f in t:\n",
    "            t0 = t0 + min(f, B)\n",
    "        mint0.append(t0)\n",
    "    tf = pd.DataFrame(curT)\n",
    "    tf['t0'] = mint0\n",
    "    res = tf[tf['t0'] == min(mint0)]\n",
    "    final_res = res.drop_duplicates()\n",
    "    final_t = np.array(final_res)[0][:-1]\n",
    "    final_label = []\n",
    "    for i in range(64):\n",
    "        if final_t[i] >= B:\n",
    "            final_label.append(i)\n",
    "    final_label_dict[id] = final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db706ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_locate_dict = {}\n",
    "for id in test_label_dict.keys():\n",
    "    temp_list = test_label_dict[id]\n",
    "    cur_label = []\n",
    "    for i in range(64):\n",
    "        if(temp_list[i] == 1):\n",
    "            cur_label.append(i)\n",
    "    test_label_locate_dict[id] = cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ee35869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 63]\n",
      "[7, 31, 32, 33, 38, 39, 49, 50, 55, 59, 63]\n",
      "------------------------------------------\n",
      "[59]\n",
      "[15, 23, 31, 47, 49, 59, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[40, 41, 42, 49, 51, 59, 63]\n",
      "------------------------------------------\n",
      "[31, 59]\n",
      "[15, 31, 59, 63]\n",
      "------------------------------------------\n",
      "[63]\n",
      "[15, 27, 41, 42, 59, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[]\n",
      "------------------------------------------\n",
      "[]\n",
      "[63]\n",
      "------------------------------------------\n",
      "[39]\n",
      "[15, 31]\n",
      "------------------------------------------\n",
      "[]\n",
      "[5, 6, 7, 14, 23, 50, 52, 63]\n",
      "------------------------------------------\n",
      "[48]\n",
      "[31, 32, 34, 47]\n",
      "------------------------------------------\n",
      "[15]\n",
      "[55]\n",
      "------------------------------------------\n",
      "[]\n",
      "[3, 4, 15, 31]\n",
      "------------------------------------------\n",
      "[]\n",
      "[55]\n",
      "------------------------------------------\n",
      "[]\n",
      "[23, 39]\n",
      "------------------------------------------\n",
      "[23, 52]\n",
      "[0, 1, 3, 4, 23, 31, 52, 63]\n",
      "------------------------------------------\n",
      "[59]\n",
      "[16, 17, 43]\n",
      "------------------------------------------\n",
      "[]\n",
      "[0, 31, 33, 47]\n",
      "------------------------------------------\n",
      "[]\n",
      "[47]\n",
      "------------------------------------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[63]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for id in final_label_dict.keys():\n",
    "    print(final_label_dict[id])\n",
    "    print(test_label_locate_dict[id])\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7048df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_label_dict = {}\n",
    "for id in final_label_dict.keys():\n",
    "    cur_label = np.zeros(64)\n",
    "    for location in final_label_dict[id]:\n",
    "        cur_label[location] = 1\n",
    "    res_test_label_dict[id] = cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "482c60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flatten_array(label_dict):\n",
    "    flatten_list = []\n",
    "    for id in label_dict.keys():\n",
    "        bitlist = label_dict[id]\n",
    "        for i in range(64):\n",
    "            flatten_list.append(bitlist[i])\n",
    "    return np.array(flatten_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f915857",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_flatten_array(res_test_label_dict)\n",
    "labels = get_flatten_array(test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7797d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测正确数量,训练集样本量:\n",
      "1146 1280\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.94      1142\n",
      "         1.0       0.67      0.06      0.11       138\n",
      "\n",
      "    accuracy                           0.90      1280\n",
      "   macro avg       0.78      0.53      0.53      1280\n",
      "weighted avg       0.87      0.90      0.85      1280\n",
      "\n",
      "混淆矩阵：\n",
      "[[1138    4]\n",
      " [ 130    8]]\n"
     ]
    }
   ],
   "source": [
    "# 每个bit是否识别正确的准确度统计\n",
    "\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(res == labels),len(labels))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(labels,res))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(labels,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b88666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsb边界是否识别正确的准确度统计\n",
    "\n",
    "right_count = 0\n",
    "total_count = 0\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i] == 1):\n",
    "        total_count = total_count + 1\n",
    "        if(res[i] == 1):\n",
    "            right_count = right_count + 1\n",
    "acc = right_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69a409e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057971014492753624"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:keras_py3.7]",
   "language": "python",
   "name": "conda-env-keras_py3.7-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
