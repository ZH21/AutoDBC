{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ff9e374",
   "metadata": {},
   "source": [
    "## 1.提取DBC文件信息转为数据域分割的GroundTruth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "0c519c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "node = []\n",
    "allDatas = []\n",
    "siganlList = []\n",
    "SignalsName = []\n",
    "messageName = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "0fcc02bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readFile(file_name):\n",
    "    global node,allDatas,siganlList,SignalsName,messageName\n",
    "    ''' 得到dbc文件的绝对路径'''\n",
    "    filePath = file_name\n",
    "    if filePath:\n",
    "        print(filePath)\n",
    "        f = open(filePath, \"r\")  # 设置文件对象\n",
    "    else:\n",
    "        print(\"读取文件失败！\")\n",
    "        return 0\n",
    "    \"\"\"\n",
    "    NodesPattern:节点\n",
    "    MessagePattern：消息\n",
    "    SignalPattern：信号\n",
    "    \"\"\"\n",
    "    NodesPattern = re.compile(r\"BU_: (.*)\", re.S)\n",
    "    MessagePattern = re.compile(r\"BO_ (.*?) (.*?): (.*?) (.*)\", re.S)\n",
    "#     SignalPattern = re.compile('''SG_ (.*?) : (.*?)\\|(.*?)@.*? \\((.*?),(.*?)\\) \\[(.*?)\\|(.*?)\\] \"(.*?)\" (.*)''', re.S)\n",
    "    SignalPattern = re.compile('''SG_ (.*?) : (.*?)\\|(.*?)@([0-9])([+|-]) \\((.*?),(.*?)\\) \\[(.*?)\\|(.*?)\\] \"(.*?)\" (.*)''', re.S)\n",
    "    DefaultValue = '''BA_ \"GenSig(.*?)\" SG_ (\\d+) signalname (\\d+);'''\n",
    "\n",
    "    line = f.readline()\n",
    "    allDatas=[]\n",
    "    while line:\n",
    "        \"\"\" 匹配出节点 \"\"\"\n",
    "        NodesSearched = re.search(NodesPattern, line.strip())\n",
    "        if NodesSearched:\n",
    "            node = NodesSearched.group(1).split(\" \")\n",
    "            #print(node)\n",
    "        \"\"\" 匹配出消息 \"\"\"\n",
    "        MessageSearched = re.search(MessagePattern, line.strip())\n",
    "        if MessageSearched:\n",
    "            siganlList.clear()\n",
    "            \"\"\"如果匹配到了message，则获取到message的相关参数 \n",
    "             比如匹配到了NM_Message_ESC_409，则会解析出改message的一些参数构成list对象['1033', 'NM_Message_ESC_409', '8', 'ESC']\n",
    "             这四个参数分别是 messgage ID ;message name ; messgae dataLenth ,message sender\n",
    "             而且把这个list对象 加在了 siganlList 索引0的位置\n",
    "            \"\"\"\n",
    "            Message = list(MessageSearched.groups())\n",
    "            siganlList.append(Message)\n",
    "            \"\"\" 只 要 message的名字 messageName 列表中\"\"\"\n",
    "            messageName.append(Message[1])\n",
    "            \"\"\"读取下一行\"\"\"\n",
    "            line = f.readline()\n",
    "            \"\"\"因为有些message并没有定义signal，所以 下一行还是message\"\"\"\n",
    "            MessageSearched = re.search(MessagePattern, line.strip())\n",
    "            SignalSearched = re.search(SignalPattern, line.strip())\n",
    "            \"\"\"下一行如果不是message的内容 就一定是signal的内容了\"\"\"\n",
    "            if not MessageSearched:\n",
    "                while SignalSearched:\n",
    "                    \"\"\"获取信号的参数追加到siganlList\"\"\"\n",
    "                    signal = list(SignalSearched.groups())\n",
    "                    siganlList.append(signal)\n",
    "                    \"\"\"只获取 signal name\"\"\"\n",
    "                    SignalsName.append(signal[0])\n",
    "\n",
    "                    # 再次解析信号，直到这个message下的信号全部解析完毕\n",
    "                    line = f.readline()\n",
    "                    SignalSearched = re.search(SignalPattern, line.strip())\n",
    "           # print(siganlList)\n",
    "            c = copy.deepcopy(siganlList)\n",
    "            allDatas.append(c)\n",
    "        else:\n",
    "            line = f.readline()\n",
    "            MessageSearched = re.search(MessagePattern, line.strip())\n",
    "    f.close()  # 将文件关闭\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "a5ae5975",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\cadillac_ct6_object.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\cadillac_ct6_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\gm_global_a_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\honda_civic_hatchback_ex_2017_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\honda_civic_sedan_16_diesel_2019_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\honda_civic_touring_2016_can_generated.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\tesla_can.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\tesla_powertrain.dbc',\n",
       " 'D:\\\\--storage--\\\\program\\\\Code\\\\jupyter-notebook\\\\CarNetworkIDS\\\\Code\\\\MyTask\\\\My_DBC\\\\tesla_radar.dbc']"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "file_names = []\n",
    "path = os.path.abspath('../My_DBC')\n",
    "# path = os.path.abspath('../opendbc-master/opendbc-master-delFalseData')\n",
    "# path = os.path.abspath('./opendbc-master/opendbc-master')\n",
    "dirs = os.listdir(path)                    # 获取指定路径下的文件\n",
    "for i in dirs:\n",
    "    if os.path.splitext(i)[1] == \".dbc\":\n",
    "        file_names.append(os.path.join(path,i))\n",
    "file_names"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4583de4e",
   "metadata": {},
   "source": [
    "## 2.处理原始bit数据和GroundTruth数据的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "702784f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_id_labels(index):\n",
    "    file_name = file_names[index]\n",
    "    readFile(file_name)\n",
    "\n",
    "    # 将DBC文件中的ID(10进制数)改为ID(16进制数)\n",
    "    data_gts = {}\n",
    "    for alldata in allDatas:\n",
    "        data_gts[str(hex(int(alldata[0][0])))[2:]] = alldata\n",
    "\n",
    "    # 得到DBC文件中各ID Message对应信号位置\n",
    "    all_id_lsbs = {}\n",
    "    for k in data_gts.keys():\n",
    "        message = data_gts[k]\n",
    "        lsb_list = []\n",
    "        series = np.zeros(64)\n",
    "        message_id = message[0][0]+\"_\"+message[0][1]\n",
    "        del message[0]\n",
    "        for signal in message:\n",
    "            start = int(signal[1])\n",
    "            length = int(signal[2])\n",
    "            endianness = int(signal[3])\n",
    "            start_row = int(start / 8)\n",
    "            start_col = 8 - (start - start_row * 8) - 1\n",
    "            new_start = start_row * 8 + start_col\n",
    "            if endianness == 0:\n",
    "                new_end = new_start + length\n",
    "                cur_lsb = new_end - 1\n",
    "            if endianness == 1:\n",
    "                cur_lsb = new_start\n",
    "            lsb_list.append(cur_lsb)\n",
    "        all_id_lsbs[k] = lsb_list\n",
    "\n",
    "    # 将各ID Message的信号位置改为 0/1 label\n",
    "    all_id_labels = {}\n",
    "    for k in all_id_lsbs:\n",
    "        cur_lsb_list = all_id_lsbs[k]\n",
    "        cur_label = np.zeros(64)\n",
    "        for cur_lsb in cur_lsb_list:\n",
    "            cur_label[cur_lsb] = 1\n",
    "        all_id_labels[k] = cur_label\n",
    "    return all_id_lsbs, all_id_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f6bad01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace(data):\n",
    "    group = data.groupby(by=\"ID\")\n",
    "    id_tracedict = {}\n",
    "    for trace in list(group):\n",
    "        id_tracedict[trace[0]] = trace[1][\"bin\"].apply(lambda x: list(x)).apply(lambda x: list(map(int, x))).tolist()\n",
    "    return id_tracedict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "63ba49c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(id_tracedict_int, all_id_labels):\n",
    "    ids = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        if(id_tracedict_int.__contains__(id) and all_id_labels.__contains__(id)):\n",
    "            ids.append(id)\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "id": "4469dbb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_id_tracedict_int(id_tracedict_int, all_id_labels):\n",
    "    true_id_tracedict_int = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        if(id_tracedict_int.__contains__(id) and all_id_labels.__contains__(id)):\n",
    "            true_id_tracedict_int.append(id_tracedict_int[id])\n",
    "    return true_id_tracedict_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "b62034f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "# 设置全局的随机种子\n",
    "random.seed(100)\n",
    "# 以id为单位shuffle\n",
    "def get_train_test_ids(id_tracedict, all_id_labels):\n",
    "    ids = get_ids(id_tracedict, all_id_labels)\n",
    "#     random.shuffle(ids)\n",
    "    ids.sort()\n",
    "    train_len = int(len(ids)*0.7)\n",
    "    train_ids = ids[:train_len]\n",
    "    test_ids = ids[train_len:]\n",
    "    return train_ids, test_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "110411d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_data_dict(cur_ids, id_tracedict_int, all_id_labels, trace_data_dict, trace_label_dict): \n",
    "    for id in cur_ids:\n",
    "        trace_data_dict[id] = id_tracedict_int[id]\n",
    "        trace_label_dict[id] = all_id_labels[id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "bd450cd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rpad_0(cur_str, width):\n",
    "    pad_len = width - len(cur_str)\n",
    "    for i in range(pad_len):\n",
    "        cur_str = cur_str + '0'\n",
    "    return cur_str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "902fd7cd",
   "metadata": {},
   "source": [
    "## 3.综合Honda和Cadillac数据，得到训练集和测试集（包括0/1Label）"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d45c577f",
   "metadata": {},
   "source": [
    "**在ID层面Shuffle**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "id": "5c9a22fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\cadillac_ct6_object.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\cadillac_ct6_powertrain.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\gm_global_a_powertrain.dbc\n"
     ]
    }
   ],
   "source": [
    "# 合并所有Cadillac以及Chevy车的Ground Truth的 0/1 label\n",
    "all_id_lsbs0, dict0 = get_id_labels(0)\n",
    "all_id_lsbs1, dict1 = get_id_labels(1)\n",
    "all_id_lsbs2, dict2 = get_id_labels(2)\n",
    "cadillac_id_labels = dict()\n",
    "for key in dict0.keys() | dict1.keys() | dict2.keys():\n",
    "    for d in (dict0, dict1, dict2):\n",
    "        if d.__contains__(key):\n",
    "            cadillac_id_labels[key] = d[key]\n",
    "            break\n",
    "cadillac_id_lsb = dict()\n",
    "for key in all_id_lsbs0.keys() | all_id_lsbs1.keys() | all_id_lsbs2.keys():\n",
    "    for d in (all_id_lsbs0, all_id_lsbs1, all_id_lsbs2):\n",
    "        if d.__contains__(key):\n",
    "            cadillac_id_lsb[key] = d[key]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "a5fc9282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_hatchback_ex_2017_can_generated.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_sedan_16_diesel_2019_can_generated.dbc\n",
      "D:\\--storage--\\program\\Code\\jupyter-notebook\\CarNetworkIDS\\Code\\MyTask\\My_DBC\\honda_civic_touring_2016_can_generated.dbc\n"
     ]
    }
   ],
   "source": [
    "# 合并所有Honda车的Ground Truth的 0/1 label\n",
    "all_id_lsbs3, dict3 = get_id_labels(3)\n",
    "all_id_lsbs4, dict4 = get_id_labels(4)\n",
    "all_id_lsbs5, dict5 = get_id_labels(5)\n",
    "honda_id_labels = dict()\n",
    "for key in dict3.keys() | dict4.keys() | dict5.keys():\n",
    "    for d in (dict3, dict4, dict5):\n",
    "        if d.__contains__(key):\n",
    "            honda_id_labels[key] = d[key]\n",
    "            break\n",
    "honda_id_lsb = dict()\n",
    "for key in all_id_lsbs3.keys() | all_id_lsbs4.keys() | all_id_lsbs5.keys():\n",
    "    for d in (all_id_lsbs3, all_id_lsbs4, all_id_lsbs5):\n",
    "        if d.__contains__(key):\n",
    "            honda_id_lsb[key] = d[key]\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "0b0622cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "oct2bin = {\"0\":\"0000\",\"1\":\"0001\",\"2\":\"0010\",\"3\":\"0011\",\"4\":\"0100\",\"5\":\"0101\",\"6\":\"0110\",\"7\":\"0111\",\"8\":\"1000\",\"9\":\"1001\",\n",
    "           \"a\":\"1010\",\"b\":\"1011\",\"c\":\"1100\",\"d\":\"1101\",\"e\":\"1110\",\"f\":\"1111\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "3d324685",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hex2bin(cur_hex):\n",
    "    res = \"\"\n",
    "    for i in cur_hex:\n",
    "        res = res + oct2bin[i]\n",
    "    res = rpad_0(res,64)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "9ae72d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车的子数据集数据\n",
    "data_hd_1 = pd.read_csv('../Data/Honda/honda001.csv')\n",
    "data_hd_2 = pd.read_csv('../Data/Honda/honda002.csv')\n",
    "# data_hd_2 = pd.read_csv('../Data/Honda/honda003.csv')\n",
    "data_hd = pd.concat([data_hd_1,data_hd_2])\n",
    "# data_hd = pd.read_csv('../Data/Honda/honda001.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "673554e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_hd[\"bin\"] = data_hd[\"Data\"].apply(lambda x: hex2bin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "2f178ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车子的数据集的大Trace dict\n",
    "id_tracedict_hd = get_trace(data_hd)\n",
    "# id_tracedict_hd = get_true_id_tracedict_int(id_tracedict_hd, honda_id_labels)\n",
    "# 得到用于训练和测试的id\n",
    "train_ids_hd, test_ids_hd = get_train_test_ids(id_tracedict_hd, honda_id_labels)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "25540b4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Cadillac车的子数据集数据\n",
    "data_cd_1 = pd.read_csv('../Data/Cadillac/CadillacCSV/001.txt.csv')\n",
    "data_cd_2 = pd.read_csv('../Data/Cadillac/CadillacCSV/002.txt.csv')\n",
    "data_cd = pd.concat([data_cd_1,data_cd_2])\n",
    "# data_cd = pd.read_csv('../Data/Cadillac/CadillacCSV/001.txt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5cdd7395",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_cd[\"bin\"] = data_cd[\"Data\"].apply(lambda x: hex2bin(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "12719425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Honda车子的数据集的大Trace dict\n",
    "id_tracedict_cd = get_trace(data_cd)\n",
    "# 得到用于训练和测试的id\n",
    "train_ids_cd, test_ids_cd = get_train_test_ids(id_tracedict_cd, cadillac_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "a7ca86d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到honda和caddilac车的trace dict及对应的label dict\n",
    "train_data_dict = {}\n",
    "train_label_dict = {}\n",
    "get_trace_data_dict(train_ids_hd, id_tracedict_hd, honda_id_labels, train_data_dict, train_label_dict)\n",
    "get_trace_data_dict(train_ids_cd, id_tracedict_cd, cadillac_id_labels, train_data_dict, train_label_dict)\n",
    "\n",
    "test_data_dict = {}\n",
    "test_label_dict = {}\n",
    "get_trace_data_dict(test_ids_hd, id_tracedict_hd, honda_id_labels, test_data_dict, test_label_dict)\n",
    "get_trace_data_dict(test_ids_cd, id_tracedict_cd, cadillac_id_labels, test_data_dict, test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "39cefd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_trace_data(id_tracedict_int, all_id_labels): \n",
    "    cur_trace_data = []\n",
    "    cur_trace_label = []\n",
    "    for id in id_tracedict_int.keys():\n",
    "        cur_trace = id_tracedict_int[id]\n",
    "        cur_label = all_id_labels[id]\n",
    "        length = len(cur_trace)\n",
    "        start = 4000\n",
    "        end = start + 1000\n",
    "        n = int((length-4000)/1000)\n",
    "        for i in range(n):\n",
    "            cur_trace_data.append(cur_trace[start: end])\n",
    "            cur_trace_label.append(cur_label)\n",
    "            start = end\n",
    "            end = start + 1000\n",
    "    return cur_trace_data, cur_trace_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "2c1ec6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label(id_tracedict_int, all_id_labels):\n",
    "    cur_trace_data, cur_trace_label = get_trace_data(id_tracedict_int, all_id_labels)\n",
    "    trace_indexs = pd.DataFrame(cur_trace_label).index.tolist()\n",
    "    random.shuffle(trace_indexs)\n",
    "    trace_data, trace_labels = np.array(cur_trace_data)[trace_indexs], np.array(cur_trace_label)[trace_indexs]\n",
    "    return trace_data, trace_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddee19b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip\n",
    "def get_bit_Flips(cur_id_traces):\n",
    "    bit_Flips = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_flip = np.append(bit_flip, 0)\n",
    "        bit_Flips.append(bit_flip)\n",
    "    return bit_Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "b4bb5bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = get_data_label(train_data_dict, train_label_dict)\n",
    "test_data, test_labels = get_data_label(test_data_dict, test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "77c5222f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_data_labels(train_data,train_labels):\n",
    "    new_train_data = []\n",
    "    new_train_labels = []\n",
    "    bit_Flips = get_bit_Flips(train_data)\n",
    "    for i in range(len(bit_Flips)):\n",
    "        if sum(bit_Flips[i]) != 0:\n",
    "            new_train_data.append(train_data[i])\n",
    "            new_train_labels.append(train_labels[i])\n",
    "    return new_train_data, new_train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afb54a73",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, train_labels = clear_data_labels(train_data,train_labels)\n",
    "test_data, test_labels = clear_data_labels(test_data,test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "759e03d2",
   "metadata": {},
   "source": [
    "## DL Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e2075a9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, LSTM, Input, Permute, BatchNormalization, Flatten, MaxPooling1D, Conv1D,Conv2D, MaxPooling2D\n",
    "from keras.layers import concatenate, add\n",
    "from keras.losses import mean_absolute_percentage_error, mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import keras.backend as K\n",
    "from sklearn import metrics\n",
    "from keras.callbacks import Callback\n",
    "from keras.models import load_model\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9849817c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### 之后需要加深Conv，增加maxpooling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "56fdf911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs = Input(shape = (1000,64,1))\n",
    "# x = keras.layers.Conv2D(15, 3, padding='same', data_format='channels_last')(inputs)\n",
    "# # x = layers.Lambda(lambda a: K.mean(a, axis=1, keepdims=True))(x)\n",
    "# x = Flatten()(x)\n",
    "# x = Dense(64, activation='relu')(x)\n",
    "# outputs = Dense(64, activation='sigmoid')(x)\n",
    "# model = Model(inputs=inputs, outputs=outputs)\n",
    "# # keras.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=None, decay=0.0, amsgrad=False)\n",
    "# keras.optimizers.Adam(lr=1e-3)\n",
    "# model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "# # model.compile(loss='binary_crossentropy',optimizer='adam',metrics=[my_acc])\n",
    "# model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956bfddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape = (1000,64,1))\n",
    "x = Conv2D(15, (3,3), padding='same', data_format='channels_last')(inputs)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=3, padding='valid')(x)\n",
    "x = Conv2D(15, (3,3), padding='same', data_format='channels_last')(x)\n",
    "x = MaxPooling2D(pool_size=(3, 3), strides=3, padding='valid')(x)\n",
    "x = Conv2D(15, (3,3), padding='same', data_format='channels_last')(x)\n",
    "x = Flatten()(x)\n",
    "x = Dropout(0.1)(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.1)(x)\n",
    "outputs = Dense(64, activation='sigmoid')(x)\n",
    "keras.optimizers.Adam(lr=1e-3)\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['acc'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "68853e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_4 = np.expand_dims(train_data, 3)\n",
    "test_data_4 = np.expand_dims(test_data, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "a7e33430",
   "metadata": {},
   "outputs": [],
   "source": [
    "mytrain_data = train_data_4\n",
    "mytrain_labels = train_labels\n",
    "\n",
    "mytest_data = test_data_4\n",
    "mytest_labels = test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "674a1703",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1719/1719 [==============================] - 157s 91ms/step - loss: 1.2289 - acc: 0.9132\n",
      "Epoch 2/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\keras\\callbacks.py:707: RuntimeWarning: Can save best model only with val_loss available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1719/1719 [==============================] - 136s 79ms/step - loss: 0.5198 - acc: 0.9662\n",
      "Epoch 3/5\n",
      "1719/1719 [==============================] - 142s 83ms/step - loss: 0.4299 - acc: 0.9717\n",
      "Epoch 4/5\n",
      "1719/1719 [==============================] - 131s 76ms/step - loss: 0.4021 - acc: 0.9745\n",
      "Epoch 5/5\n",
      "1719/1719 [==============================] - 130s 76ms/step - loss: 0.3981 - acc: 0.9750\n"
     ]
    }
   ],
   "source": [
    "callbacks_list = [\n",
    "    keras.callbacks.EarlyStopping(\n",
    "        monitor='acc',\n",
    "        patience=5,\n",
    "    ),\n",
    "    keras.callbacks.ModelCheckpoint(\n",
    "        filepath='./Model/My_model/my_model.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "    ),\n",
    "    keras.callbacks.ReduceLROnPlateau(\n",
    "#     monitor='val_loss',\n",
    "    monitor='acc',\n",
    "    factor=0.2,\n",
    "    patience=2,\n",
    "    )\n",
    "]\n",
    "\n",
    "history = model.fit(mytrain_data, mytrain_labels,\n",
    "     epochs=5,\n",
    "     batch_size=10,\n",
    "     callbacks=callbacks_list\n",
    "#      validation_split=0.1\n",
    "#      validation_data=(myval_data, myval_labels)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "6465b831",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "acc = history.history['acc']\n",
    "loss = history.history['loss']\n",
    "epochs = range(1, len(acc) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "634f8cae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title('Accuracy')\n",
    "plt.plot(epochs, acc, 'red', label='Training acc')\n",
    "plt.plot(epochs, loss, 'blue', label='Training loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "d8271ef4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "107314 110016\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      1.00      0.99    101298\n",
      "         1.0       0.97      0.71      0.82      8718\n",
      "\n",
      "    accuracy                           0.98    110016\n",
      "   macro avg       0.97      0.85      0.90    110016\n",
      "weighted avg       0.98      0.98      0.97    110016\n",
      "\n",
      "混淆矩阵：\n",
      "[[101131    167]\n",
      " [  2535   6183]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_prob = model.predict(mytrain_data)\n",
    "predict_target_msb_label = (predict_target_msb_prob > 0.5).astype(int)\n",
    "predict_target_msb_1D = predict_target_msb_label.flatten()\n",
    "train_labels_1D = mytrain_labels.flatten()\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_1D == train_labels_1D),len(train_labels_1D))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(train_labels_1D,predict_target_msb_1D))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(train_labels_1D,predict_target_msb_1D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "e39c7180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "24342 26112\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      0.96      0.96     25230\n",
      "         1.0       0.14      0.19      0.16       882\n",
      "\n",
      "    accuracy                           0.93     26112\n",
      "   macro avg       0.55      0.57      0.56     26112\n",
      "weighted avg       0.94      0.93      0.94     26112\n",
      "\n",
      "混淆矩阵：\n",
      "[[24177  1053]\n",
      " [  717   165]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_prob =model.predict(mytest_data)\n",
    "predict_target_test_msb_label = (predict_target_test_msb_prob > 0.5).astype(int)\n",
    "predict_target_test_msb_1D = predict_target_test_msb_label.flatten()\n",
    "test_labels_1D = mytest_labels.flatten()\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_1D == test_labels_1D),len(test_labels_1D))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(test_labels_1D,predict_target_test_msb_1D))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(test_labels_1D,predict_target_test_msb_1D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f56a466c",
   "metadata": {},
   "source": [
    "## READ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97cc8706",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip\n",
    "import math\n",
    "inf = -11\n",
    "def get_preparation(trace_data):\n",
    "    bit_Flips = []\n",
    "    Magnitudes = []\n",
    "    for i in range(len(trace_data)):\n",
    "        messagelist = trace_data[i]\n",
    "        trace_len = len(messagelist)\n",
    "        bit_flip = np.zeros(64)\n",
    "        magnitude = np.zeros(64)\n",
    "        previous = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(64):\n",
    "                if item[ix] != previous[ix]:\n",
    "                    bit_flip[ix] = bit_flip[ix] + 1\n",
    "            previous = item\n",
    "        for ix in range(64):\n",
    "            bit_flip[ix] = bit_flip[ix] / trace_len\n",
    "            if bit_flip[ix] == 0:\n",
    "                cur_magnitude = inf\n",
    "            else:\n",
    "                cur_magnitude = math.log10(bit_flip[ix])\n",
    "            magnitude[ix] = math.ceil(cur_magnitude)\n",
    "        bit_Flips.append(bit_flip)\n",
    "        Magnitudes.append(magnitude)\n",
    "    return bit_Flips, Magnitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1408324a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase1(magnitude):\n",
    "    ref = []\n",
    "    prevMagnitude = magnitude[0]\n",
    "    ixS = 0\n",
    "    for ix in range(64):\n",
    "        if magnitude[ix] < prevMagnitude:\n",
    "            ref.append((ixS, ix-1))\n",
    "            ixS = ix\n",
    "        prevMagnitude = magnitude[ix]\n",
    "    ref.append((ixS, 63))\n",
    "    return ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "adf3be6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matchCounter(sublist):\n",
    "    if(sublist[-1] != 1):\n",
    "        return -1\n",
    "    ixS = len(sublist)-1\n",
    "    for i in range(len(sublist)-2,-1,-1):\n",
    "        if sublist[i] == (sublist[i+1] / 2):\n",
    "            ixS = i\n",
    "    return ixS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c45df11e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_phase2(ref, bit_flip, magnitude):\n",
    "    rRef = []\n",
    "    for sign in ref:\n",
    "        (ixS, ixE) = sign\n",
    "        mgt = magnitude[ixS: ixE+1]\n",
    "        mu = np.mean(bit_flip[ixS: ixE+1])\n",
    "        std = np.std(bit_flip[ixS: ixE+1])\n",
    "        if magnitude[ixE] == 0:\n",
    "            Sctr = matchCounter(bit_flip[ixS: ixE+1])\n",
    "#             print(Sctr)\n",
    "            if Sctr >= 0:\n",
    "                rRef.append((ixS, Sctr, \"PHYSVAL\"))\n",
    "                rRef.append((Sctr, ixE, \"COUNTER\"))\n",
    "        else:\n",
    "            exit = False\n",
    "            for Scrc in range(ixS, ixE+1):\n",
    "                if not exit:\n",
    "#                     print(Scrc)\n",
    "                    if sum(magnitude[Scrc: (ixE+1)]) == 0 and mu >= (0.5-std) and mu <= (0.5+std):\n",
    "                        rRef.append((Scrc, ixE, \"CRC\"))\n",
    "                        rRef.append((ixS, Scrc, \"PHYSVAL\"))\n",
    "                        exit = True\n",
    "                else:\n",
    "                    break\n",
    "    return rRef"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b65f9da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def position2preds(preds_ref):\n",
    "    preds = []\n",
    "    for i in range(len(preds_ref)):\n",
    "        cur_ref = preds_ref[i]\n",
    "        cur_preds = np.zeros(64)\n",
    "        for signal in cur_ref:\n",
    "            cur_preds[signal[1]] = 1\n",
    "        preds.append(cur_preds)\n",
    "    return np.array(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f18ae75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boundary_score(y_true, y_pred):\n",
    "    new_labels = []\n",
    "    new_preds = []\n",
    "    for i in range(len(y_true)):\n",
    "        if(y_true[i] == 1):\n",
    "            new_labels.append(y_true[i])\n",
    "            new_preds.append(y_pred[i])\n",
    "    return np.array(new_labels), np.array(new_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "94e3a5db",
   "metadata": {},
   "outputs": [],
   "source": [
    "fasle_i = [7 ,8 ,11 ,12 ,14 ,15 ,16 ,17]\n",
    "false_id = []\n",
    "for i in fasle_i:\n",
    "    false_id.append(list(test_data_dict.keys())[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "f27d284d",
   "metadata": {},
   "outputs": [],
   "source": [
    "origin_trace = []\n",
    "origin_label = []\n",
    "for id in test_data_dict.keys():\n",
    "    if id not in false_id:\n",
    "        origin_trace.append(test_data_dict[id])\n",
    "        origin_label.append(test_label_dict[id])\n",
    "origin_trace = np.array(origin_trace)\n",
    "origin_label = np.array(origin_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "36f43369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['305', '309', '324', '374', '405', '4d1', '4d4', '4e1', '514', '52a', '52b', '530', '541', '641', '778', '787', 'be', 'c9', 'd1', 'f1'])"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "29e53873",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ids_cd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "962c5a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_ids_hd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "id": "9e4520a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "READ_test_data = origin_trace\n",
    "READ_test_labels = origin_label\n",
    "\n",
    "# READ_test_data = test_data\n",
    "# READ_test_labels = test_labels\n",
    "\n",
    "# READ_test_data = np.array(cur_data)\n",
    "# READ_test_labels =  np.array(cur_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "1a6e9cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_flip_dict, magnitude_dict = get_preparation(READ_test_data)\n",
    "preds_ref = []\n",
    "preds_rRef = []\n",
    "for i in range(len(magnitude_dict)):\n",
    "    ref = get_phase1(magnitude_dict[i])\n",
    "    rRef = get_phase2(ref, bit_flip_dict[i], magnitude_dict[i])\n",
    "    preds_rRef.append(rRef)\n",
    "    preds_ref.append(ref)\n",
    "preds = position2preds(preds_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "f49a7a37",
   "metadata": {},
   "outputs": [],
   "source": [
    "# READ_test_labels[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "19f207a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bit_flip_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "5935dd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(np.arange(64), bit_flip_dict[],label=\"bit-flip\")\n",
    "# # plt.bar(np.arange(64), READ_test_labels[10],label=\"label\",color=\"black\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "378ce051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(np.arange(64), bit_flip_dict[3],label=\"bit-flip\")\n",
    "# plt.bar(np.arange(64), preds[3],label=\"preds\")\n",
    "# plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "ddf7f18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.bar(np.arange(64), magnitude_dict[1],label=\"magnitude\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "feb8cdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "667 768\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.92      0.94      0.93       678\n",
      "         1.0       0.42      0.34      0.38        90\n",
      "\n",
      "    accuracy                           0.87       768\n",
      "   macro avg       0.67      0.64      0.65       768\n",
      "weighted avg       0.86      0.87      0.86       768\n",
      "\n",
      "混淆矩阵：\n",
      "[[636  42]\n",
      " [ 59  31]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(\"测试集:\")\n",
    "preds_msb_1D = preds.flatten()\n",
    "test_labels_1D = READ_test_labels.flatten()\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(preds_msb_1D == test_labels_1D),len(test_labels_1D))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(test_labels_1D,preds_msb_1D))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(test_labels_1D,preds_msb_1D))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d081b1",
   "metadata": {},
   "source": [
    "## 4.CAN-D数据特征提取函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ad9ae42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_constant_bit(cur_trace_data, cur_trace_label, bit_Flips):\n",
    "    for i in range(len(bit_Flips)):\n",
    "        cur_bit_flip = bit_Flips[i]\n",
    "        cur_constant_bits = []\n",
    "        for j in range(64):\n",
    "            if cur_bit_flip[j] == 0:\n",
    "                cur_constant_bits.append(j)\n",
    "        a = cur_trace_data[i]\n",
    "        b = []\n",
    "        for temp in a:\n",
    "            b.append([temp[j] for j in range(len(temp)) if j not in cur_constant_bits])\n",
    "        cur_trace_data[i] = b\n",
    "        temp = []\n",
    "        for j in range(len(cur_trace_label[i])):\n",
    "            next_j = j+1\n",
    "            if j not in cur_constant_bits:\n",
    "                if next_j in cur_constant_bits:\n",
    "                    temp.append(1)\n",
    "                else:\n",
    "                    temp.append(cur_trace_label[i][j])\n",
    "        cur_trace_label[i] = temp\n",
    "#         cur_trace_label[i] = [temp[j] for j in range(len(temp)) if j not in cur_constant_bits]\n",
    "        temp = bit_Flips[i]\n",
    "        bit_Flips[i] = [temp[j] for j in range(len(temp)) if j not in cur_constant_bits]\n",
    "    return cur_trace_data, cur_trace_label, bit_Flips"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "41c2fe74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用READ方法计算bit-flip的联合概率\n",
    "def get_bit_Flip_LHs(cur_id_traces):\n",
    "    bit_Flip_LHs = []\n",
    "    bit_Flip_LH_nos = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        messagelist = cur_id_traces[i]\n",
    "        trace_len = len(messagelist)\n",
    "        message_len = len(messagelist[0])\n",
    "        bit_flip_LH = np.zeros(message_len)\n",
    "        bit_flip_LH_no = np.zeros(message_len)\n",
    "        previous_LH = messagelist[0]\n",
    "        for item in messagelist:\n",
    "            for ix in range(message_len-1):\n",
    "                if item[ix] != previous_LH[ix] and item[ix+1] != previous_LH[ix+1]:\n",
    "                    bit_flip_LH[ix] = bit_flip_LH[ix] + 1\n",
    "                if item[ix] == previous_LH[ix] and item[ix+1] == previous_LH[ix+1]:\n",
    "                    bit_flip_LH_no[ix] = bit_flip_LH_no[ix] + 1\n",
    "            previous_LH = item\n",
    "        for ix in range(message_len-1):\n",
    "            bit_flip_LH[ix] = bit_flip_LH[ix] / trace_len\n",
    "            bit_flip_LH_no[ix] = bit_flip_LH_no[ix] / trace_len\n",
    "\n",
    "        bit_flip_LH = np.append(bit_flip_LH, 0)\n",
    "        bit_flip_LH = np.append(bit_flip_LH, 0)\n",
    "        bit_flip_LH_no = np.append(bit_flip_LH_no, 0)\n",
    "        bit_flip_LH_no = np.append(bit_flip_LH_no, 0)\n",
    "\n",
    "        bit_Flip_LHs.append(bit_flip_LH)\n",
    "        bit_Flip_LH_nos.append(bit_flip_LH_no)\n",
    "    return bit_Flip_LHs, bit_Flip_LH_nos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "cdb2cfd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reverse_id_tracelist 通过大端bit序列得到小端bit序列\n",
    "def get_reverse_id_traces(cur_id_traces):\n",
    "    reverse_id_traces = []\n",
    "    for i in range(len(cur_id_traces)):\n",
    "        id_tracelist = cur_id_traces[i]\n",
    "        reverse_id_tracelist = []\n",
    "        for item in id_tracelist:\n",
    "            cur_tracelist = [0,1,2,3,4,5,6,7]\n",
    "            cur_temp = []\n",
    "            count = 7\n",
    "            for i in range(64):\n",
    "                cur_temp.append(item[i])\n",
    "                if (i+1)%8 == 0:\n",
    "                    cur_tracelist[count] = cur_temp\n",
    "                    count = count - 1\n",
    "                    cur_temp = []\n",
    "            reverse_id_tracelist.append(np.concatenate(cur_tracelist).tolist())\n",
    "        reverse_id_traces[i] = reverse_id_tracelist\n",
    "    return reverse_id_traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "e6e8adb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到每个bit的15个特征\n",
    "def get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i):\n",
    "    f1 = bit_Flips[i][ix]\n",
    "#     print(bit_Flips[i], i, ix)\n",
    "    f2 = bit_Flips_LH[i][ix] / bit_Flips[i][ix+1]\n",
    "    f3 = bit_Flips_LH[i][ix] / bit_Flips[i][ix]\n",
    "    f4 = bit_Flip_LH_nos[i][ix] / (1 - bit_Flips[i][ix+1])\n",
    "    f5 = bit_Flip_LH_nos[i][ix] / (1 - bit_Flips[i][ix])\n",
    "    return np.array([f1,f2,f3,f4,f5])\n",
    "\n",
    "def get_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i):\n",
    "    cur_bit_feature = []\n",
    "    feature_sub1 = get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i)\n",
    "    feature_sub2 = get_sub_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix+1, i)\n",
    "    feature_sub3 = feature_sub2 - feature_sub1\n",
    "    return np.concatenate((feature_sub1,feature_sub2,feature_sub3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "6606d718",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 为每个bit赋予15个特征\n",
    "def get_bit_features_list(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos):\n",
    "    bit_features_list = []\n",
    "    for i in range(len(bit_Flips)):\n",
    "        bit_features = []\n",
    "        for ix in range(len(bit_Flips[i])-2):\n",
    "            bit_features.append(get_feature(bit_Flips, bit_Flips_LH, bit_Flip_LH_nos, ix, i))\n",
    "        bit_features_list.append(bit_features)\n",
    "    return bit_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "a6a3d992",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 小端转成大端的正常格式，方便与上边生成的ground truth label匹配\n",
    "def LE_to_BE(reverse_bit_features_list):\n",
    "    bit_features_list = []\n",
    "    for i in range(len(reverse_bit_features_list)):\n",
    "        item = reverse_bit_features_dict[i]\n",
    "        cur_bit_features = [0,1,2,3,4,5,6,7]\n",
    "        cur_temp = []\n",
    "        count = 7\n",
    "        for i in range(64):\n",
    "            cur_temp.append(item[i])\n",
    "            if (i+1)%8 == 0:\n",
    "                cur_bit_features[count] = cur_temp\n",
    "                count = count - 1\n",
    "                cur_temp = []\n",
    "        bit_features_list.append(np.concatenate(cur_bit_features).tolist())\n",
    "    return bit_features_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "110be394",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到Trace与Ground Truth都存在的id\n",
    "def get_all_datas_labels(bit_features_list, cur_id_labels):\n",
    "    alldatas = []\n",
    "    alllabels = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for i in range(len(cur_features)):\n",
    "            alldatas.append(cur_features[i])\n",
    "            alllabels.append(int(cur_labels[i]))\n",
    "    return alldatas, alllabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "05836d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_shuffle_data_label(cur_trace_data, cur_trace_label):\n",
    "    trace_indexs = pd.DataFrame(cur_trace_label).index.tolist()\n",
    "    random.shuffle(trace_indexs)\n",
    "    trace_data, trace_labels = np.array(cur_trace_data)[trace_indexs], np.array(cur_trace_label)[trace_indexs]\n",
    "    return trace_data, trace_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f2f583f",
   "metadata": {},
   "source": [
    "## 5.训练大端的RF模型，去掉constant bit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "986c47e5",
   "metadata": {},
   "source": [
    "### 预训练模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "66e9c690",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_id_traces, train_id_labels = get_trace_data(train_data_dict, train_label_dict)\n",
    "bit_Flips_train = get_bit_Flips(train_id_traces)\n",
    "train_id_traces, train_id_labels, bit_Flips_train = del_constant_bit(train_id_traces, train_id_labels, bit_Flips_train)\n",
    "bit_Flip_LHs_train, bit_Flip_LH_nos_train = get_bit_Flip_LHs(train_id_traces)\n",
    "bit_features_list_train = get_bit_features_list(bit_Flips_train, bit_Flip_LHs_train, bit_Flip_LH_nos_train)\n",
    "traindatas_msb, trainlabels_msb = get_all_datas_labels(bit_features_list_train, train_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "40f6d1f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_id_traces, test_id_labels = get_trace_data(test_data_dict, test_label_dict)\n",
    "bit_Flips_test = get_bit_Flips(test_id_traces)\n",
    "test_id_traces, test_id_labels, bit_Flips_test = del_constant_bit(test_id_traces, test_id_labels, bit_Flips_test)\n",
    "bit_Flip_LHs_test, bit_Flip_LH_nos_test = get_bit_Flip_LHs(test_id_traces)\n",
    "bit_features_list_test = get_bit_features_list(bit_Flips_test, bit_Flip_LHs_test, bit_Flip_LH_nos_test)\n",
    "testdatas_msb, testlabels_msb = get_all_datas_labels(bit_features_list_test, test_id_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "08b3f4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_msb, trainlabels_msb = get_shuffle_data_label(traindatas_msb, trainlabels_msb)\n",
    "testdatas_msb, testlabels_msb = get_shuffle_data_label(testdatas_msb, testlabels_msb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "f255541d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traindata_msb = pd.DataFrame(traindatas_msb)\n",
    "Traindata_msb['label'] = np.array(trainlabels_msb)\n",
    "Traindata_msb = Traindata_msb.fillna(0)\n",
    "traindatas_msb = np.array(Traindata_msb.iloc[:,:15])\n",
    "trainlabels_msb = np.array(Traindata_msb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "82ee54b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata_msb = pd.DataFrame(testdatas_msb)\n",
    "Testdata_msb['label'] = np.array(testlabels_msb)\n",
    "Testdata_msb = Testdata_msb.fillna(0)\n",
    "testdatas_msb = np.array(Testdata_msb.iloc[:,:15])\n",
    "testlabels_msb = np.array(Testdata_msb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "6f06bd9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "40919 41188\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     34887\n",
      "           1       0.98      0.97      0.98      6301\n",
      "\n",
      "    accuracy                           0.99     41188\n",
      "   macro avg       0.99      0.99      0.99     41188\n",
      "weighted avg       0.99      0.99      0.99     41188\n",
      "\n",
      "混淆矩阵：\n",
      "[[34787   100]\n",
      " [  169  6132]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "8094 8977\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      7403\n",
      "           1       0.71      0.73      0.72      1574\n",
      "\n",
      "    accuracy                           0.90      8977\n",
      "   macro avg       0.83      0.83      0.83      8977\n",
      "weighted avg       0.90      0.90      0.90      8977\n",
      "\n",
      "混淆矩阵：\n",
      "[[6944  459]\n",
      " [ 424 1150]]\n"
     ]
    }
   ],
   "source": [
    "#随机森林方法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "model_msb = RandomForestClassifier(n_estimators= 30)\n",
    "model_msb.fit(traindatas_msb, trainlabels_msb)\n",
    "\n",
    "print(\"训练集:\")\n",
    "predict_target_msb = model_msb.predict(traindatas_msb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb == trainlabels_msb),len(trainlabels_msb))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_msb,predict_target_msb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb,predict_target_msb))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_msb =model_msb.predict(testdatas_msb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb == testlabels_msb),len(testlabels_msb))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_msb,predict_target_test_msb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb,predict_target_test_msb))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e91464",
   "metadata": {},
   "source": [
    "### 微调模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "68bc5dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "train_id_traces_f, train_id_labels_f = get_trace_data(train_data_dict, train_label_dict)\n",
    "bit_Flips_train_f = get_bit_Flips(train_id_traces_f)\n",
    "bit_Flip_LHs_train_f, bit_Flip_LH_nos_train_f = get_bit_Flip_LHs(train_id_traces_f)\n",
    "bit_features_list_train_f = get_bit_features_list(bit_Flips_train_f, bit_Flip_LHs_train_f, bit_Flip_LH_nos_train_f)\n",
    "traindatas_msb_f, trainlabels_msb_f = get_all_datas_labels(bit_features_list_train_f, train_id_labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "2f9108e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "test_id_traces_f, test_id_labels_f = get_trace_data(test_data_dict, test_label_dict)\n",
    "bit_Flips_test_f = get_bit_Flips(test_id_traces_f)\n",
    "bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f = get_bit_Flip_LHs(test_id_traces_f)\n",
    "bit_features_list_test_f = get_bit_features_list(bit_Flips_test_f, bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f)\n",
    "testdatas_msb_f, testlabels_msb_f = get_all_datas_labels(bit_features_list_test_f, test_id_labels_f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "f442a8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_msb_f, trainlabels_msb_f = get_shuffle_data_label(traindatas_msb_f, trainlabels_msb_f)\n",
    "testdatas_msb_f, testlabels_msb_f = get_shuffle_data_label(testdatas_msb_f, testlabels_msb_f)\n",
    "\n",
    "Traindata_msb_f = pd.DataFrame(traindatas_msb_f)\n",
    "Traindata_msb_f['label'] = np.array(trainlabels_msb_f)\n",
    "Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "traindatas_msb_f = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "trainlabels_msb_f = np.array(Traindata_msb_f.iloc[:,-1])\n",
    "\n",
    "Testdata_msb_f = pd.DataFrame(testdatas_msb_f)\n",
    "Testdata_msb_f['label'] = np.array(testlabels_msb_f)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "testdatas_msb_f = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "testlabels_msb_f = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "400d5e1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1719, 1000, 64)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(train_id_traces_f).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "c2d4dbef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_nonobvious_boundary(cur_features, j):\n",
    "    if j == 0:\n",
    "        if cur_features[1][0] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    if j == 63:\n",
    "        if cur_features[62][0] != 0:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "#     print(j, len(cur_features))\n",
    "    if cur_features[j-1][0] != 0 and cur_features[j+1][0] != 0:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "8815ca1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tun_data_label(bit_features_list, cur_id_labels):\n",
    "    nonobvious_boundaries = []\n",
    "    nonobvious_boundaries_label = []\n",
    "    obvious_boundaries = []\n",
    "    obvious_boundaries_label = []\n",
    "    negative_bit = []\n",
    "    negativ_bit_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 0:\n",
    "                negative_bit.append(cur_features[j])\n",
    "                negativ_bit_label.append(int(cur_labels[j]))\n",
    "            elif is_nonobvious_boundary(cur_features, j):\n",
    "                nonobvious_boundaries.append(cur_features[j])\n",
    "                nonobvious_boundaries_label.append(int(cur_labels[j]))\n",
    "            else:\n",
    "                obvious_boundaries.append(cur_features[j])\n",
    "                obvious_boundaries_label.append(int(cur_labels[j]))\n",
    "\n",
    "    len_nb = len(nonobvious_boundaries_label)\n",
    "    len_ne = int(len_nb/8 * 4)\n",
    "    len_ob = int(len_nb/8)\n",
    "    train_data = np.concatenate([nonobvious_boundaries, negative_bit[:len_ne], obvious_boundaries[:len_ob]])\n",
    "    train_label = np.concatenate([nonobvious_boundaries_label, negativ_bit_label[:len_ne], obvious_boundaries_label[:len_ob]])\n",
    "    tun_data, tun_label = get_shuffle_data_label(train_data, train_label)\n",
    "    return tun_data, tun_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "a3d21b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_test_data_label(bit_features_list, cur_id_labels):\n",
    "    nonobvious_boundaries = []\n",
    "    nonobvious_boundaries_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 1 and is_nonobvious_boundary(cur_features, j):\n",
    "                nonobvious_boundaries.append(cur_features[j])\n",
    "                nonobvious_boundaries_label.append(int(cur_labels[j]))\n",
    "    test_data, test_label = get_shuffle_data_label(nonobvious_boundaries, nonobvious_boundaries_label)\n",
    "    return test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "5383e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label_boundary(bit_features_list, cur_id_labels):\n",
    "    boundaries = []\n",
    "    boundaries_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 1:\n",
    "                boundaries.append(cur_features[j])\n",
    "                boundaries_label.append(int(cur_labels[j]))\n",
    "    test_data, test_label = get_shuffle_data_label(boundaries, boundaries_label)\n",
    "    return test_data, test_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "57ad4fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_label_boundary_constant(bit_features_list, cur_id_labels):\n",
    "    nonobvious_boundaries = []\n",
    "    nonobvious_boundaries_label = []\n",
    "    negative_bit = []\n",
    "    negativ_bit_label = []\n",
    "    for i in range(len(bit_features_list)):\n",
    "        cur_features = bit_features_list[i]\n",
    "        cur_labels = cur_id_labels[i]\n",
    "        for j in range(len(cur_features)):\n",
    "            if cur_labels[j] == 0:\n",
    "                negative_bit.append(cur_features[j])\n",
    "                negativ_bit_label.append(int(cur_labels[j]))\n",
    "            elif is_nonobvious_boundary(cur_features, j):\n",
    "                nonobvious_boundaries.append(cur_features[j])\n",
    "                nonobvious_boundaries_label.append(int(cur_labels[j]))\n",
    "    train_data = np.concatenate([nonobvious_boundaries, negative_bit])\n",
    "    train_label = np.concatenate([nonobvious_boundaries_label, negativ_bit_label])\n",
    "    tun_data, tun_label = get_shuffle_data_label(train_data, train_label)\n",
    "    return tun_data, tun_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "be55daa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_data, tun_label = get_tun_data_label(bit_features_list_train_f, train_id_labels_f)\n",
    "\n",
    "Traindata_msb_f = pd.DataFrame(tun_data)\n",
    "Traindata_msb_f['label'] = np.array(tun_label)\n",
    "Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "tun_data = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "tun_label = np.array(Traindata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "408a1894",
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_data_2, tun_label_2 = get_tun_data_label(bit_features_list_test_f, test_id_labels_f)\n",
    "\n",
    "Traindata_msb_f = pd.DataFrame(tun_data_2)\n",
    "Traindata_msb_f['label'] = np.array(tun_label_2)\n",
    "Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "tun_data_2 = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "tun_label_2 = np.array(Traindata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "11cac30e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tun_test_data, tun_test_label = get_test_data_label(bit_features_list_test_f, test_id_labels_f)\n",
    "\n",
    "Testdata_msb_f = pd.DataFrame(tun_test_data)\n",
    "Testdata_msb_f['label'] = np.array(tun_test_label)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "tun_test_data = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "tun_test_label = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e6894112",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_features_list_f = np.concatenate([bit_features_list_train_f,bit_features_list_test_f])\n",
    "id_labels_f = np.concatenate([train_id_labels_f,test_id_labels_f])\n",
    "\n",
    "tun_test_data_all, tun_test_label_all = get_test_data_label(bit_features_list_f, id_labels_f)\n",
    "\n",
    "Testdata_msb_f = pd.DataFrame(tun_test_data_all)\n",
    "Testdata_msb_f['label'] = np.array(tun_test_label_all)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "tun_test_data_all = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "tun_test_label_all = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c481cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "bit_features_list_f = np.concatenate([bit_features_list_train_f,bit_features_list_test_f])\n",
    "id_labels_f = np.concatenate([train_id_labels_f,test_id_labels_f])\n",
    "\n",
    "tun_test_data_boundary, tun_test_label_boundary = get_data_label_boundary(bit_features_list_f, id_labels_f)\n",
    "\n",
    "Testdata_msb_f = pd.DataFrame(tun_test_data_boundary)\n",
    "Testdata_msb_f['label'] = np.array(tun_test_label_boundary)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "tun_test_data_boundary = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "tun_test_label_boundary = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "c7607190",
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_data, f1_label = get_data_label_boundary_constant(bit_features_list_train_f, train_id_labels_f)\n",
    "\n",
    "Traindata_msb_f = pd.DataFrame(f1_data)\n",
    "Traindata_msb_f['label'] = np.array(f1_label)\n",
    "Traindata_msb_f = Traindata_msb_f.fillna(0)\n",
    "f1_data = np.array(Traindata_msb_f.iloc[:,:15])\n",
    "f1_label = np.array(Traindata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "c9327fa1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 200, 'min_samples_leaf': 3, 'max_features': 8, 'max_depth': 6}\n",
      "-0.03635618956285463\n",
      "RandomForestClassifier(max_depth=6, max_features=8, min_samples_leaf=3,\n",
      "                       n_estimators=200)\n"
     ]
    }
   ],
   "source": [
    "param_distribution = [\n",
    "    {'n_estimators' : [30, 60, 90,150,200,250], 'max_features' : [2, 4, 6, 8,10], \n",
    "     'max_depth':[1,2,3,4,5,6],'min_samples_leaf':[1,2,3,4]},\n",
    "#     {'bootstrap' : [False], 'n_estimators' : [3, 10], 'max_features' : [2, 3, 4]},\n",
    "]\n",
    " \n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# from scikitlearn.scikit_learn.sklearn.model_selection._search import RandomizedSearchCV\n",
    " \n",
    "random_search_cv = RandomizedSearchCV(model_msb,\n",
    "                                      param_distribution,\n",
    "                                      n_iter = 30,#从param_distribution里sample出多少个参数集合\n",
    "                                      cv = 10,\n",
    "                                      scoring='neg_mean_squared_error',\n",
    "#                                       scoring=my_scores,\n",
    "                                      n_jobs = 1) #有多少任务并行处理\n",
    "# random_search_cv.fit(traindatas_msb_f, trainlabels_msb_f)\n",
    "random_search_cv.fit(tun_data, tun_label)\n",
    " \n",
    "# 在超参数搜索时有cross_validation机制: 训练集分成n份，n-1训练，最后一份验证.\n",
    "# 在超参数搜索完之后，会在全部训练集上用新的参数再训练一遍\n",
    " \n",
    "print(random_search_cv.best_params_) #最好参数\n",
    "print(random_search_cv.best_score_) #最好分值\n",
    "print(random_search_cv.best_estimator_) #最好的model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "e6c83e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_tunning = random_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "c92d31bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "96784 103685\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.96    101298\n",
      "           1       0.25      0.98      0.40      2387\n",
      "\n",
      "    accuracy                           0.93    103685\n",
      "   macro avg       0.63      0.96      0.68    103685\n",
      "weighted avg       0.98      0.93      0.95    103685\n",
      "\n",
      "混淆矩阵：\n",
      "[[94440  6858]\n",
      " [   43  2344]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(f1_data)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == f1_label),len(f1_label))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(f1_label,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(f1_label,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2bd81145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "3135 3393\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.98      0.89      1044\n",
      "           1       0.99      0.90      0.94      2349\n",
      "\n",
      "    accuracy                           0.92      3393\n",
      "   macro avg       0.90      0.94      0.92      3393\n",
      "weighted avg       0.94      0.92      0.93      3393\n",
      "\n",
      "混淆矩阵：\n",
      "[[1026   18]\n",
      " [ 240 2109]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(tun_data)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == tun_label),len(tun_label))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_label,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_label,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71631424",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "507 620\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.42      0.59       191\n",
      "           1       0.79      0.99      0.88       429\n",
      "\n",
      "    accuracy                           0.82       620\n",
      "   macro avg       0.88      0.71      0.74       620\n",
      "weighted avg       0.85      0.82      0.79       620\n",
      "\n",
      "混淆矩阵：\n",
      "[[ 81 110]\n",
      " [  3 426]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(tun_data_2)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == tun_label_2),len(tun_label_2))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_label_2,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_label_2,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "52d0936f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "382 382\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00       382\n",
      "\n",
      "    accuracy                           1.00       382\n",
      "   macro avg       1.00      1.00      1.00       382\n",
      "weighted avg       1.00      1.00      1.00       382\n",
      "\n",
      "混淆矩阵：\n",
      "[[382]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(tun_test_data)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == tun_test_label),len(tun_test_label))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_test_label,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_test_label,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "a4d03fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "2470 2470\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       1.00      1.00      1.00      2470\n",
      "\n",
      "    accuracy                           1.00      2470\n",
      "   macro avg       1.00      1.00      1.00      2470\n",
      "weighted avg       1.00      1.00      1.00      2470\n",
      "\n",
      "混淆矩阵：\n",
      "[[2470]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(tun_test_data_all)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == tun_test_label_all),len(tun_test_label_all))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_test_label_all,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_test_label_all,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "966cf648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "5004 9600\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         0\n",
      "           1       1.00      0.52      0.69      9600\n",
      "\n",
      "    accuracy                           0.52      9600\n",
      "   macro avg       0.50      0.26      0.34      9600\n",
      "weighted avg       1.00      0.52      0.69      9600\n",
      "\n",
      "混淆矩阵：\n",
      "[[   0    0]\n",
      " [4596 5004]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(tun_test_data_boundary)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == tun_test_label_boundary),len(tun_test_label_boundary))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(tun_test_label_boundary,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(tun_test_label_boundary,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "f6062682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2,    5,   13, ..., 9597, 9598, 9599], dtype=int64),)"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(predict_target_test_msb_f == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "94621c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "79240 120000\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.67      0.79    111450\n",
      "           1       0.11      0.52      0.18      8550\n",
      "\n",
      "    accuracy                           0.66    120000\n",
      "   macro avg       0.53      0.59      0.48    120000\n",
      "weighted avg       0.89      0.66      0.74    120000\n",
      "\n",
      "混淆矩阵：\n",
      "[[74831 36619]\n",
      " [ 4141  4409]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "11401 16128\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.72      0.82     15078\n",
      "           1       0.12      0.57      0.20      1050\n",
      "\n",
      "    accuracy                           0.71     16128\n",
      "   macro avg       0.54      0.64      0.51     16128\n",
      "weighted avg       0.91      0.71      0.78     16128\n",
      "\n",
      "混淆矩阵：\n",
      "[[10806  4272]\n",
      " [  455   595]]\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(traindatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == trainlabels_msb_f),len(trainlabels_msb_f))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_msb_f,predict_target_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb_f,predict_target_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "c6d70cd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "22099 25216\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.89      0.93     24460\n",
      "           1       0.09      0.36      0.15       756\n",
      "\n",
      "    accuracy                           0.88     25216\n",
      "   macro avg       0.54      0.63      0.54     25216\n",
      "weighted avg       0.95      0.88      0.91     25216\n",
      "\n",
      "混淆矩阵：\n",
      "[[21827  2633]\n",
      " [  484   272]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(testdatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == testlabels_msb_f),len(testlabels_msb_f))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_msb_f,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "f939a43a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cur_data_dict = {}\n",
    "cur_label_dict = {}\n",
    "id = \"309\"\n",
    "cur_data_dict[id] = test_data_dict[id]\n",
    "cur_label_dict[id] = test_label_dict[id]\n",
    "cur_data,cur_label = get_trace_data(cur_data_dict, cur_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "530337f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:6: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "bit_Flips_test_f = get_bit_Flips(cur_data)\n",
    "bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f = get_bit_Flip_LHs(test_id_traces_f)\n",
    "bit_features_list_test_f = get_bit_features_list(bit_Flips_test_f, bit_Flip_LHs_test_f, bit_Flip_LH_nos_test_f)\n",
    "curdatas_msb_f, curlabels_msb_f = get_all_datas_labels(bit_features_list_test_f, cur_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "fb2883b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata_msb_f = pd.DataFrame(curdatas_msb_f)\n",
    "Testdata_msb_f['label'] = np.array(curlabels_msb_f)\n",
    "Testdata_msb_f = Testdata_msb_f.fillna(0)\n",
    "curdatas_msb_f = np.array(Testdata_msb_f.iloc[:,:15])\n",
    "curlabels_msb_f = np.array(Testdata_msb_f.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "d70dad96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "779 896\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.88      0.92       798\n",
      "           1       0.44      0.76      0.56        98\n",
      "\n",
      "    accuracy                           0.87       896\n",
      "   macro avg       0.71      0.82      0.74       896\n",
      "weighted avg       0.91      0.87      0.88       896\n",
      "\n",
      "混淆矩阵：\n",
      "[[705  93]\n",
      " [ 24  74]]\n"
     ]
    }
   ],
   "source": [
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(curdatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == curlabels_msb_f),len(curlabels_msb_f))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(curlabels_msb_f,predict_target_test_msb_f))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(curlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "87a7de68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_list(arr, length):\n",
    "    res = []\n",
    "    last_i = 0\n",
    "    for i in range(length,len(arr),length):\n",
    "        res.append(arr[last_i:i])\n",
    "        last_i = i\n",
    "    res.append(arr[last_i:len(arr)])\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "83ff155f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "def cal_score_mean(labels, preds):\n",
    "    new_labels = clip_list(labels,64)\n",
    "    new_preds = clip_list(preds,64)\n",
    "    f1_score = 0\n",
    "    precision_score = 0\n",
    "    recall_score = 0\n",
    "    for i in range(len(new_labels)):\n",
    "        cur_label = new_labels[i]\n",
    "        cur_pred = new_preds[i]\n",
    "        f1_score = f1_score + sklearn.metrics.f1_score(cur_label, cur_pred)\n",
    "        precision_score = precision_score + sklearn.metrics.precision_score(cur_label, cur_pred)\n",
    "        recall_score = recall_score + sklearn.metrics.recall_score(cur_label, cur_pred)\n",
    "    res_f1_score = f1_score / len(new_labels)\n",
    "    res_precision_score = precision_score / len(new_labels)\n",
    "    res_recall_score = recall_score / len(new_labels)\n",
    "    return res_precision_score, res_recall_score, res_f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "1ac1bcbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "79240 120000\n",
      "训练集精确度等指标：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.10733179380598669 0.5150875805675805 0.17253723704633905\n",
      "混淆矩阵：\n",
      "[[74831 36619]\n",
      " [ 4141  4409]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "11401 16128\n",
      "测试集精确度等指标：\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.12101254383273913 0.5534653507867794 0.19326915181059473\n",
      "混淆矩阵：\n",
      "[[10806  4272]\n",
      " [  455   595]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "D:\\--storage--\\program\\application\\windows-installer\\Miniconda3\\Miniconda3\\envs\\Commonl_Py3.6\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1248: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "print(\"训练集:\")\n",
    "predict_target_msb_f = model_tunning.predict(traindatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_msb_f == trainlabels_msb_f),len(trainlabels_msb_f))\n",
    "print(\"训练集精确度等指标：\")\n",
    "res_precision_score, res_recall_score, res_f1_score = cal_score_mean(trainlabels_msb_f,predict_target_msb_f)\n",
    "print(res_precision_score, res_recall_score, res_f1_score)\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_msb_f,predict_target_msb_f))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_msb_f =model_tunning.predict(testdatas_msb_f)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_msb_f == testlabels_msb_f),len(testlabels_msb_f))\n",
    "print(\"测试集精确度等指标：\")\n",
    "res_precision_score_test, res_recall_score_test, res_f1_score_test = cal_score_mean(testlabels_msb_f,predict_target_test_msb_f)\n",
    "print(res_precision_score_test, res_recall_score_test, res_f1_score_test)\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e846933c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(\"训练集:\")\n",
    "# predict_target_msb_f = model_msb.predict(traindatas_msb_f)\n",
    "# print(\"预测正确数量,训练集样本量:\")\n",
    "# print(sum(predict_target_msb_f == trainlabels_msb_f),len(trainlabels_msb_f))\n",
    "# print(\"训练集精确度等指标：\")\n",
    "# print(metrics.classification_report(trainlabels_msb_f,predict_target_msb_f))\n",
    "# print(\"混淆矩阵：\")\n",
    "# print(metrics.confusion_matrix(trainlabels_msb_f,predict_target_msb_f))\n",
    "\n",
    "# print(\"测试集:\")\n",
    "# predict_target_test_msb_f =model.predict(testdatas_msb_f)\n",
    "# print(\"预测正确数量,训练集样本量:\")\n",
    "# print(sum(predict_target_test_msb_f == testlabels_msb_f),len(testlabels_msb_f))\n",
    "# print(\"测试集精确度等指标：\")\n",
    "# print(metrics.classification_report(testlabels_msb_f,predict_target_test_msb_f))\n",
    "# print(\"混淆矩阵：\")\n",
    "# print(metrics.confusion_matrix(testlabels_msb_f,predict_target_test_msb_f))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e4adcf",
   "metadata": {},
   "source": [
    "## 训练小端的RF模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "11dfd71f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "reverse_train_data_dict = get_reverse_id_tracedict(train_data_dict)\n",
    "reverse_bit_flip_dict_train = get_bit_flip_dict(reverse_train_data_dict)\n",
    "reverse_bit_flip_LH_dict_train, reverse_bit_flip_LH_no_dict_train = get_bit_flip_LH_dict(reverse_train_data_dict)\n",
    "reverse_bit_features_dict_train = get_bit_features_dict(reverse_bit_flip_dict_train, reverse_bit_flip_LH_dict_train, reverse_bit_flip_LH_no_dict_train)\n",
    "bit_features_dict_train_lsb = LE_to_BE(reverse_bit_features_dict_train)\n",
    "traindatas_lsb, trainlabels_lsb = get_all_datas_labels(bit_features_dict_train_lsb, train_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1cf86408",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\Users\\Linever\\AppData\\Roaming\\Python\\Python36\\site-packages\\ipykernel_launcher.py:5: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "reverse_test_data_dict = get_reverse_id_tracedict(test_data_dict)\n",
    "reverse_bit_flip_dict_test = get_bit_flip_dict(reverse_test_data_dict)\n",
    "reverse_bit_flip_LH_dict_test, reverse_bit_flip_LH_no_dict_test = get_bit_flip_LH_dict(reverse_test_data_dict)\n",
    "reverse_bit_features_dict_test = get_bit_features_dict(reverse_bit_flip_dict_test, reverse_bit_flip_LH_dict_test, reverse_bit_flip_LH_no_dict_test)\n",
    "bit_features_dict_test_lsb = LE_to_BE(reverse_bit_features_dict_test)\n",
    "testdatas_lsb, testlabels_lsb = get_all_datas_labels(bit_features_dict_test_lsb, test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0150d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "traindatas_lsb, trainlabels_lsb = get_shuffle_data_label(traindatas_lsb, trainlabels_lsb)\n",
    "testdatas_lsb, testlabels_lsb = get_shuffle_data_label(testdatas_lsb, testlabels_lsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5c11316f",
   "metadata": {},
   "outputs": [],
   "source": [
    "Traindata_lsb = pd.DataFrame(traindatas_lsb)\n",
    "Traindata_lsb['label'] = np.array(trainlabels_lsb)\n",
    "Traindata_lsb = Traindata_lsb.fillna(0)\n",
    "traindatas_lsb = np.array(Traindata_lsb.iloc[:,:15])\n",
    "trainlabels_lsb = np.array(Traindata_lsb.iloc[:,-1])\n",
    "\n",
    "Testdata_lsb = pd.DataFrame(testdatas_lsb)\n",
    "Testdata_lsb['label'] = np.array(testlabels_lsb)\n",
    "Testdata_lsb = Testdata_lsb.fillna(0)\n",
    "testdatas_lsb = np.array(Testdata_lsb.iloc[:,:15])\n",
    "testlabels_lsb = np.array(Testdata_lsb.iloc[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c13e221c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集:\n",
      "预测正确数量,训练集样本量:\n",
      "2717 2944\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      1.00      0.96      2644\n",
      "           1       0.95      0.26      0.40       300\n",
      "\n",
      "    accuracy                           0.92      2944\n",
      "   macro avg       0.94      0.63      0.68      2944\n",
      "weighted avg       0.93      0.92      0.90      2944\n",
      "\n",
      "混淆矩阵：\n",
      "[[2640    4]\n",
      " [ 223   77]]\n",
      "测试集:\n",
      "预测正确数量,训练集样本量:\n",
      "1138 1280\n",
      "测试集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.99      0.94      1142\n",
      "           1       0.43      0.09      0.14       138\n",
      "\n",
      "    accuracy                           0.89      1280\n",
      "   macro avg       0.66      0.54      0.54      1280\n",
      "weighted avg       0.85      0.89      0.85      1280\n",
      "\n",
      "混淆矩阵：\n",
      "[[1126   16]\n",
      " [ 126   12]]\n"
     ]
    }
   ],
   "source": [
    "#随机森林方法\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "model_lsb = RandomForestClassifier(n_estimators= 30)\n",
    "model_lsb.fit(traindatas_lsb, trainlabels_lsb)\n",
    "\n",
    "print(\"训练集:\")\n",
    "predict_target_lsb = model_lsb.predict(traindatas_lsb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_lsb == trainlabels_lsb), len(trainlabels_lsb))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(trainlabels_lsb, predict_target_lsb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(trainlabels_lsb, predict_target_lsb))\n",
    "\n",
    "print(\"测试集:\")\n",
    "predict_target_test_lsb = model_lsb.predict(testdatas_lsb)\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(predict_target_test_lsb == testlabels_lsb),len(testlabels_lsb))\n",
    "print(\"测试集精确度等指标：\")\n",
    "print(metrics.classification_report(testlabels_lsb, predict_target_test_lsb))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(testlabels_lsb, predict_target_test_lsb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c31dee1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./Model/CAN-D_FR_LSB.model']"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# RF大端模型保存\n",
    "joblib.dump(filename='./Model/CAN-D_FR_LSB.model', value=model_lsb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "10724fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "V = []\n",
    "setlist1 = ['JB', 'C']\n",
    "setlist2 = ['JB', 'JL', 'C']\n",
    "setlist3 = ['JL', 'C']\n",
    "flag = True\n",
    "count = 0\n",
    "for a in setlist1:\n",
    "    for b in setlist2:\n",
    "        for c in setlist2:\n",
    "            for d in setlist2:\n",
    "                for e in setlist2:\n",
    "                    for f in setlist2:\n",
    "                        for g in setlist2:\n",
    "                            for h in setlist3:\n",
    "                                v = [a,b,c,d,e,f,g,h]\n",
    "                                for i in range(8):\n",
    "                                    if(v[i] == 'JB' and v[i+1] == 'JL'):\n",
    "                                        flag = False\n",
    "                                        break\n",
    "                                    if(v[i] == 'JB' and i<6 and v[i+2] == 'JL'):\n",
    "                                        flag = False\n",
    "                                        break\n",
    "                                if flag == True:\n",
    "                                    V.append(v)\n",
    "                                    count = count + 1\n",
    "                                flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d02dda49",
   "metadata": {},
   "outputs": [],
   "source": [
    "E = []\n",
    "for v in V:\n",
    "    e = ['C', 'C', 'C', 'C', 'C', 'C', 'C', 'C']\n",
    "    for i in range(8):\n",
    "        if v[i] == 'JB':\n",
    "            e[i] = 'B'\n",
    "            e[i+1] = 'B'\n",
    "        if v[i] == 'JL':\n",
    "            e[i] = 'L'\n",
    "            e[i-1] = 'L'\n",
    "    E.append(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "6d2e44de",
   "metadata": {},
   "outputs": [],
   "source": [
    "EB = pd.DataFrame(E).replace('C', 'B')\n",
    "EB = np.array(EB).tolist()\n",
    "\n",
    "EL = pd.DataFrame(E).replace('C', 'L')\n",
    "EL = np.array(EL).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "a307fd1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 得到所有可能的信号标记集合T\n",
    "def get_T(proba_msb, proba_lsb):\n",
    "    T = []\n",
    "    for e in EB:\n",
    "        t = []\n",
    "        for i in range(8):\n",
    "            if e[i] == 'B':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_msb[j])\n",
    "            if e[i] == 'L':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_lsb[j])\n",
    "        T.append(t)\n",
    "    for e in EL:\n",
    "        t = []\n",
    "        for i in range(8):\n",
    "            if e[i] == 'B':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_msb[j])\n",
    "            if e[i] == 'L':\n",
    "                start = i * 8\n",
    "                end = (i+1) * 8\n",
    "                for j in range(start, end):\n",
    "                    t.append(proba_lsb[j])\n",
    "        T.append(t)\n",
    "    return T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d4d51985",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_proba_msb_dict = {}\n",
    "for id in bit_features_dict_test.keys():\n",
    "    cur_predictproba_msb = []\n",
    "    temp = pd.DataFrame(bit_features_dict_test[id]).fillna(0)\n",
    "    cur_predict_proba_msb = model_msb.predict_proba(temp)\n",
    "    for prediction in cur_predict_proba_msb:\n",
    "        cur_predictproba_msb.append(prediction[1])\n",
    "    predict_proba_msb_dict[id] = cur_predictproba_msb\n",
    "    \n",
    "predict_proba_lsb_dict = {}\n",
    "for id in bit_features_dict_test_lsb.keys():\n",
    "    cur_predictproba_lsb = []\n",
    "    temp = pd.DataFrame(bit_features_dict_test_lsb[id]).fillna(0)\n",
    "    cur_predict_proba_lsb = model_lsb.predict_proba(temp)\n",
    "    for prediction in cur_predict_proba_lsb:\n",
    "        cur_predictproba_lsb.append(prediction[1])\n",
    "    predict_proba_lsb_dict[id] = cur_predictproba_lsb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "8584235b",
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 0.6\n",
    "final_label_dict = {}\n",
    "for id in predict_proba_msb_dict.keys():\n",
    "    curT = get_T(predict_proba_msb_dict[id], predict_proba_lsb_dict[id])\n",
    "    mint0 = []\n",
    "    for t in curT:\n",
    "        t0 = 0\n",
    "        for f in t:\n",
    "            t0 = t0 + min(f, B)\n",
    "        mint0.append(t0)\n",
    "    tf = pd.DataFrame(curT)\n",
    "    tf['t0'] = mint0\n",
    "    res = tf[tf['t0'] == min(mint0)]\n",
    "    final_res = res.drop_duplicates()\n",
    "    final_t = np.array(final_res)[0][:-1]\n",
    "    final_label = []\n",
    "    for i in range(64):\n",
    "        if final_t[i] >= B:\n",
    "            final_label.append(i)\n",
    "    final_label_dict[id] = final_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "db706ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label_locate_dict = {}\n",
    "for id in test_label_dict.keys():\n",
    "    temp_list = test_label_dict[id]\n",
    "    cur_label = []\n",
    "    for i in range(64):\n",
    "        if(temp_list[i] == 1):\n",
    "            cur_label.append(i)\n",
    "    test_label_locate_dict[id] = cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "1ee35869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[59, 63]\n",
      "[7, 31, 32, 33, 38, 39, 49, 50, 55, 59, 63]\n",
      "------------------------------------------\n",
      "[59]\n",
      "[15, 23, 31, 47, 49, 59, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[40, 41, 42, 49, 51, 59, 63]\n",
      "------------------------------------------\n",
      "[31, 59]\n",
      "[15, 31, 59, 63]\n",
      "------------------------------------------\n",
      "[63]\n",
      "[15, 27, 41, 42, 59, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[]\n",
      "------------------------------------------\n",
      "[]\n",
      "[63]\n",
      "------------------------------------------\n",
      "[39]\n",
      "[15, 31]\n",
      "------------------------------------------\n",
      "[]\n",
      "[5, 6, 7, 14, 23, 50, 52, 63]\n",
      "------------------------------------------\n",
      "[48]\n",
      "[31, 32, 34, 47]\n",
      "------------------------------------------\n",
      "[15]\n",
      "[55]\n",
      "------------------------------------------\n",
      "[]\n",
      "[3, 4, 15, 31]\n",
      "------------------------------------------\n",
      "[]\n",
      "[55]\n",
      "------------------------------------------\n",
      "[]\n",
      "[23, 39]\n",
      "------------------------------------------\n",
      "[23, 52]\n",
      "[0, 1, 3, 4, 23, 31, 52, 63]\n",
      "------------------------------------------\n",
      "[59]\n",
      "[16, 17, 43]\n",
      "------------------------------------------\n",
      "[]\n",
      "[0, 31, 33, 47]\n",
      "------------------------------------------\n",
      "[]\n",
      "[47]\n",
      "------------------------------------------\n",
      "[]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 57, 58, 59, 60, 61, 62, 63]\n",
      "------------------------------------------\n",
      "[]\n",
      "[63]\n",
      "------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for id in final_label_dict.keys():\n",
    "    print(final_label_dict[id])\n",
    "    print(test_label_locate_dict[id])\n",
    "    print(\"------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7048df7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "res_test_label_dict = {}\n",
    "for id in final_label_dict.keys():\n",
    "    cur_label = np.zeros(64)\n",
    "    for location in final_label_dict[id]:\n",
    "        cur_label[location] = 1\n",
    "    res_test_label_dict[id] = cur_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "482c60d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_flatten_array(label_dict):\n",
    "    flatten_list = []\n",
    "    for id in label_dict.keys():\n",
    "        bitlist = label_dict[id]\n",
    "        for i in range(64):\n",
    "            flatten_list.append(bitlist[i])\n",
    "    return np.array(flatten_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "0f915857",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = get_flatten_array(res_test_label_dict)\n",
    "labels = get_flatten_array(test_label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "7797d00e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "预测正确数量,训练集样本量:\n",
      "1146 1280\n",
      "训练集精确度等指标：\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.90      1.00      0.94      1142\n",
      "         1.0       0.67      0.06      0.11       138\n",
      "\n",
      "    accuracy                           0.90      1280\n",
      "   macro avg       0.78      0.53      0.53      1280\n",
      "weighted avg       0.87      0.90      0.85      1280\n",
      "\n",
      "混淆矩阵：\n",
      "[[1138    4]\n",
      " [ 130    8]]\n"
     ]
    }
   ],
   "source": [
    "# 每个bit是否识别正确的准确度统计\n",
    "\n",
    "print(\"预测正确数量,训练集样本量:\")\n",
    "print(sum(res == labels),len(labels))\n",
    "print(\"训练集精确度等指标：\")\n",
    "print(metrics.classification_report(labels,res))\n",
    "print(\"混淆矩阵：\")\n",
    "print(metrics.confusion_matrix(labels,res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "9b88666f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lsb边界是否识别正确的准确度统计\n",
    "\n",
    "right_count = 0\n",
    "total_count = 0\n",
    "for i in range(len(labels)):\n",
    "    if(labels[i] == 1):\n",
    "        total_count = total_count + 1\n",
    "        if(res[i] == 1):\n",
    "            right_count = right_count + 1\n",
    "acc = right_count / total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "69a409e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.057971014492753624"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:Commonl_Py3.6]",
   "language": "python",
   "name": "conda-env-Commonl_Py3.6-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
